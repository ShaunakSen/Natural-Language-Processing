{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Advanced NLP with spaCy.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMghY0DM6vcqFRw8AsaUPcA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShaunakSen/Natural-Language-Processing/blob/master/Advanced_NLP_with_spaCy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqfRdeWMbqjJ",
        "colab_type": "text"
      },
      "source": [
        "## Advanced NLP with spaCy\n",
        "\n",
        "> Based on the official course: https://course.spacy.io/en\n",
        "\n",
        "---\n",
        "\n",
        "### Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n95ciw4RbNxI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U spacy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7wntApobW82",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U spacy-lookups-data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjeW6SGybdKl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python -m spacy download en_core_web_sm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMfH8WReb1uQ",
        "colab_type": "text"
      },
      "source": [
        "### Chapter 1: Finding words, phrases, names and concepts\n",
        "\n",
        "#### Introduction to spaCy\n",
        "\n",
        "**The nlp object**\n",
        "\n",
        "At the center of spaCy is the object containing the processing pipeline. We usually call this variable \"nlp\".\n",
        "\n",
        "For example, to create an English nlp object, you can import the English language class from `spacy.lang.en` and instantiate it. You can use the nlp object like a function to analyze text.\n",
        "\n",
        "It contains all the different components in the pipeline.\n",
        "\n",
        "It also includes language-specific rules used for tokenizing the text into words and punctuation. spaCy supports a variety of languages that are available in `spacy.lang`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrnSPjWebeuJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the English language class\n",
        "from spacy.lang.en import English\n",
        "\n",
        "# Create the nlp object\n",
        "nlp = English()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NV1LCv_ecVtH",
        "colab_type": "text"
      },
      "source": [
        "**The Doc Object**\n",
        "\n",
        "When you process a text with the nlp object, spaCy creates a Doc object – short for \"document\". The Doc lets you access information about the text in a structured way, and no information is lost.\n",
        "\n",
        "The Doc behaves like a normal Python sequence by the way and lets you iterate over its tokens, or get a token by its index. But more on that later!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjZE51BhcRDk",
        "colab_type": "code",
        "outputId": "c9bdb9ab-92a6-40c6-9528-bfe5cbe54d1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# Created by processing a string of text with the nlp object\n",
        "\n",
        "doc = nlp(text=\"Hello world!\")\n",
        "\n",
        "# Iterate over tokens in a Doc\n",
        "for token in doc:\n",
        "    print (token.text) "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello\n",
            "world\n",
            "!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nj-6cPitcxZa",
        "colab_type": "text"
      },
      "source": [
        "**The token object**\n",
        "![](https://course.spacy.io/doc.png)\n",
        "\n",
        "Token objects represent the tokens in a document – for example, a word or a punctuation character.\n",
        "\n",
        "Token objects also provide various attributes that let you access more information about the tokens. For example, the .text attribute returns the verbatim token text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jy7Pwhr9cu1V",
        "colab_type": "code",
        "outputId": "85e9c676-302a-461e-dd31-dace2b76f810",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Index into the Doc to get a single Token\n",
        "token = doc[1]\n",
        "\n",
        "# Get the token text via the .text attribute\n",
        "print(token.text)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "world\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXhgx--kdKuf",
        "colab_type": "text"
      },
      "source": [
        "**The span object**\n",
        "\n",
        "*A Span object is a slice of the document consisting of one or more tokens*. \n",
        "\n",
        "> It's only a view of the Doc and doesn't contain any data itself.\n",
        "\n",
        "To create a span, you can use Python's slice notation. For example, 1:3 will create a slice starting from the token at position 1, up to – but not including! – the token at position 3.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4Mvpd27c7lP",
        "colab_type": "code",
        "outputId": "a8024c4a-f0e1-4339-daa6-aeb244dda9a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "span = doc[1:3]\n",
        "\n",
        "print(span.text)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "world!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPM562uwdpP4",
        "colab_type": "text"
      },
      "source": [
        "**Token attributes**\n",
        "\n",
        "Here you can see some of the available token attributes:\n",
        "\n",
        "i is the index of the token within the parent document.\n",
        "\n",
        "text returns the token text.\n",
        "\n",
        "is_alpha, is_punct and like_num return boolean values indicating whether the token consists of alphabetic characters, whether it's punctuation or whether it resembles a number. For example, a token \"10\" – one, zero – or the word \"ten\" – T, E, N.\n",
        "\n",
        "These attributes are also called lexical attributes: **they refer to the entry in the vocabulary and don't depend on the token's context**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODlnwwEBdogI",
        "colab_type": "code",
        "outputId": "f22b2427-fd86-4ce4-f662-f0d0b69108ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "doc = nlp(\"It costs $5. Ten £ only\")\n",
        "\n",
        "print(\"Index:   \", [token.i for token in doc])\n",
        "print(\"Text:    \", [token.text for token in doc])\n",
        "\n",
        "print(\"is_alpha:\", [token.is_alpha for token in doc])\n",
        "print(\"is_punct:\", [token.is_punct for token in doc])\n",
        "print(\"like_num:\", [token.like_num for token in doc])\n",
        "print(\"is_currency:\", [token.is_currency for token in doc])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index:    [0, 1, 2, 3, 4, 5, 6, 7]\n",
            "Text:     ['It', 'costs', '$', '5', '.', 'Ten', '£', 'only']\n",
            "is_alpha: [True, True, False, False, False, True, False, True]\n",
            "is_punct: [False, False, False, False, True, False, False, False]\n",
            "like_num: [False, False, False, True, False, True, False, False]\n",
            "is_currency: [False, False, True, False, False, False, True, False]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8TX4EoJf4Jm",
        "colab_type": "text"
      },
      "source": [
        "#### Exercises (slightly complicated ones)\n",
        "\n",
        "In this example, you’ll use spaCy’s Doc and Token objects, and lexical attributes to find percentages in a text. You’ll be looking for two subsequent tokens: a number and a percent sign.\n",
        "\n",
        "- Use the like_num token attribute to check whether a token in the doc resembles a number.\n",
        "- Get the token following the current token in the document. The index of the next token in the doc is token.i + 1.\n",
        "- Check whether the next token’s text attribute is a percent sign ”%“."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CXda3nHrL8_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "5e624008-e474-444a-9ed2-2566bda73aca"
      },
      "source": [
        "# Process the text\n",
        "doc = nlp(\n",
        "    \"In 1990, more than 60% of people in East Asia were in extreme poverty. \"\n",
        "    \"Now less than 4% are.\"\n",
        ")\n",
        "\n",
        "for token in doc:\n",
        "    if token.like_num:\n",
        "        next_token = doc[token.i + 1]\n",
        "        if next_token.text == '%':\n",
        "            print (token.text)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60\n",
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCMTGGqQsfdO",
        "colab_type": "text"
      },
      "source": [
        "#### Statistical models\n",
        "\n",
        "Some of the most interesting things you can analyze are context-specific: for example, whether a word is a verb or whether a span of text is a person name.\n",
        "\n",
        "\n",
        "Statistical models enable spaCy to make predictions in context. This usually includes part-of speech tags, syntactic dependencies and named entities.\n",
        "\n",
        "- Part-of-speech tags\n",
        "- Syntactic dependencies\n",
        "- Named entities\n",
        "\n",
        "- Trained on labeled example texts\n",
        "- Can be updated with more examples to fine-tune predictions\n",
        "\n",
        "spaCy provides a number of pre-trained model packages you can download using the spacy download command. For example, the `\"en_core_web_sm`\" package is a small English model that supports all core capabilities and is trained on web text.\n",
        "\n",
        "The `spacy.load` method loads a model package by name and returns an nlp object.\n",
        "\n",
        "The package provides the binary weights that enable spaCy to make predictions.\n",
        "\n",
        "It also includes the vocabulary, and meta information to tell spaCy which language class to use and how to configure the processing pipeline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4-yqXzQsgkd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cP7n1GG0k-sv",
        "colab_type": "text"
      },
      "source": [
        "**Predicting Part-of-speech Tags**\n",
        "\n",
        "1. First, we load the small English model and receive an nlp object.\n",
        "\n",
        "2. Next, we're processing the text \"She ate the pizza\".\n",
        "\n",
        "3. For each token in the doc, we can print the text and the .pos_ attribute, the predicted part-of-speech tag.\n",
        "\n",
        "> In spaCy, attributes that return strings usually end with an underscore – attributes without the underscore return an integer ID value.\n",
        "\n",
        "Here, the model correctly predicted \"ate\" as a verb and \"pizza\" as a noun.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtvGAEu0kx-m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "967eddcf-64af-42fd-f1cf-bab0ced8f7d3"
      },
      "source": [
        "doc = nlp(\"She ate the pizza!\")\n",
        "\n",
        "for token in doc:\n",
        "    print (token.text, token.pos_)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "She PRON\n",
            "ate VERB\n",
            "the DET\n",
            "pizza NOUN\n",
            "! PUNCT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwF_ShcylczN",
        "colab_type": "text"
      },
      "source": [
        "**Predicting Syntactic Dependencies**\n",
        "\n",
        "In addition to the part-of-speech tags, we can also predict how the words are related. For example, whether a word is the subject of the sentence or an object.\n",
        "\n",
        "- The `.dep_` attribute returns the predicted dependency label.\n",
        "\n",
        "- The `.head` attribute returns the syntactic head token. You can also think of it as the parent token this word is attached to."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VClrIwvTlZQY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "d9e9c03e-8eba-4774-9db0-266c0fc54ea7"
      },
      "source": [
        "for token in doc:\n",
        "    print(token.text, token.pos_, token.dep_, token.head.text)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "She PRON nsubj ate\n",
            "ate VERB ROOT ate\n",
            "the DET det pizza\n",
            "pizza NOUN dobj ate\n",
            "! PUNCT punct ate\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pb_Zj7RSmEtl",
        "colab_type": "text"
      },
      "source": [
        "**Dependency label scheme**\n",
        "\n",
        "To describe syntactic dependencies, spaCy uses a standardized label scheme. Here's an example of some common labels:\n",
        "\n",
        "\n",
        "![](https://course.spacy.io/dep_example.png)\n",
        "\n",
        "\n",
        "\n",
        "![](https://i.ibb.co/2nxYpjX/diag1.png)\n",
        "\n",
        "The pronoun \"She\" is a nominal subject attached to the verb – in this case, to \"ate\".\n",
        "\n",
        "The noun \"pizza\" is a direct object attached to the verb \"ate\". It is eaten by the subject, \"she\".\n",
        "\n",
        "The determiner \"the\", also known as an article, is attached to the noun \"pizza\".\n",
        "\n",
        "**Predicting Named Entities**\n",
        "\n",
        "![](https://course.spacy.io/ner_example.png)\n",
        "\n",
        "Named entities are \"real world objects\" that are assigned a name – for example, a person, an organization or a country.\n",
        "\n",
        "The `doc.ents` property lets you access the named entities predicted by the model.\n",
        "\n",
        "It returns an iterator of Span objects, so we can print the entity text and the entity label using the `.label_` attribute.\n",
        "\n",
        "In this case, the model is correctly predicting \"Apple\" as an organization, \"U.K.\" as a geopolitical entity and \"$1 billion\" as money.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bN4bYCMDl3X3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "e3234e98-1a37-42d6-c908-42a2954a4e76"
      },
      "source": [
        "# Process a text\n",
        "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
        "\n",
        "# Iterate over the predicted entities\n",
        "for ent in doc.ents:\n",
        "    print (ent.text, ent.label_)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Apple ORG\n",
            "U.K. GPE\n",
            "$1 billion MONEY\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GW1alWfhroys",
        "colab_type": "text"
      },
      "source": [
        "**Tip: the spacy.explain method**\n",
        "\n",
        "A quick tip: To get definitions for the most common tags and labels, you can use the spacy.explain helper function.\n",
        "\n",
        "For example, \"GPE\" for geopolitical entity isn't exactly intuitive – but spacy.explain can tell you that it refers to countries, cities and states.\n",
        "\n",
        "The same works for part-of-speech tags and dependency labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WNiG2-ErjPI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "4ff467bc-5064-4e00-ef2b-46a6694d0e44"
      },
      "source": [
        "print (spacy.explain(\"GPE\"))\n",
        "print (spacy.explain(\"NNP\"))\n",
        "print (spacy.explain(\"dobj\"))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Countries, cities, states\n",
            "noun, proper singular\n",
            "direct object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QiNpQXdr-Y4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}