{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Understanding Doc2Vec.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOqx7jrEFY7KgDQ36gVh3xz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShaunakSen/Natural-Language-Processing/blob/master/Understanding_Doc2Vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPxPW_xRu65A"
      },
      "source": [
        "## Doc2Vec Model\r\n",
        "\r\n",
        "> Notes on the article: https://radimrehurek.com/gensim/auto_examples/tutorials/run_doc2vec_lee.html\r\n",
        "\r\n",
        "Doc2Vec is a Model that represents each Document as a Vector. This tutorial introduces the model and demonstrates how to train and assess it.\r\n",
        "\r\n",
        "\r\n",
        "### Review: Bag-of-words\r\n",
        "\r\n",
        "This model transforms each document to a fixed-length vector of integers. For example, given the sentences:\r\n",
        "\r\n",
        "- `John likes to watch movies. Mary likes movies too.`\r\n",
        "- `John also likes to watch football games. Mary hates football.`\r\n",
        "\r\n",
        "The model outputs the vectors:\r\n",
        "\r\n",
        "- `[1, 2, 1, 1, 2, 1, 1, 0, 0, 0, 0]`\r\n",
        "- `[1, 1, 1, 1, 0, 1, 0, 1, 2, 1, 1]`\r\n",
        "\r\n",
        "Each vector has 10 elements, where each element counts the number of times a particular word occurred in the document. The order of elements is arbitrary. In the example above, the order of the elements corresponds to the words: \r\n",
        "`[\"John\", \"likes\", \"to\", \"watch\", \"movies\", \"Mary\", \"too\", \"also\", \"football\", \"games\", \"hates\"]`.\r\n",
        "\r\n",
        "Bag-of-words models are surprisingly effective, but have several weaknesses.\r\n",
        "\r\n",
        "First, they lose all information about word order: “John likes Mary” and “Mary likes John” correspond to identical vectors. There is a solution: bag of n-grams models consider word phrases of length n to represent documents as fixed-length vectors to capture local word order but suffer from data sparsity and high dimensionality.\r\n",
        "\r\n",
        "Second, the model does not attempt to learn the meaning of the underlying words, and as a consequence, the distance between vectors doesn’t always reflect the difference in meaning. The Word2Vec model addresses this second problem.\r\n",
        "\r\n",
        "### Review: Word2Vec Model\r\n",
        "\r\n",
        "Word2Vec is a more recent model that embeds words in a lower-dimensional vector space using a shallow neural network. The result is a set of word-vectors where vectors close together in vector space have similar meanings based on context, and word-vectors distant to each other have differing meanings. For example, strong and powerful would be close together and strong and Paris would be relatively far.\r\n",
        "\r\n",
        "With the Word2Vec model, we can calculate the vectors for each word in a document. But what if we want to calculate a vector for the entire document? We could **average** the vectors for each word in the document - while this is quick and crude, it can often be useful. However, there is a better way…\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCwh3NDtu2NX"
      },
      "source": [
        "import logging\r\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aI-mf4OGvDrT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}