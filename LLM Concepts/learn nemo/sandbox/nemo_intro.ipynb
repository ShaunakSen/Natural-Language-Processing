{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nemo Guardrails - Introduction\n",
    "\n",
    "> https://www.pinecone.io/learn/nemo-guardrails-intro/\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import AzureOpenAI, AzureChatOpenAI, AzureOpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(\"/Users/shaunaksen/Documents/personal-projects/Natural-Language-Processing/LLM Concepts/llamaindex_tutorials/knowledge_graphs/.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print (os.environ['AZURE_API_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shaunaksen/miniconda3/envs/shaunak_llm/lib/python3.10/site-packages/langchain_community/llms/__init__.py:166: LangChainDeprecationWarning: `` was deprecated in LangChain 0.0.22 and will be removed in 0.2. An updated version of the  exists in the langchain-community package and should be used instead. To use it run `pip install -U langchain-community` and import as `from langchain_community.chat_models import ChatDatabricks`.\n",
      "  warn_deprecated(\n",
      "/Users/shaunaksen/miniconda3/envs/shaunak_llm/lib/python3.10/site-packages/langchain_community/llms/__init__.py:323: LangChainDeprecationWarning: `` was deprecated in LangChain 0.0.22 and will be removed in 0.2. An updated version of the  exists in the langchain-community package and should be used instead. To use it run `pip install -U langchain-community` and import as `from langchain_community.chat_models import ChatMlflow`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from nemoguardrails import LLMRails, RailsConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4_turbo = AzureOpenAI(\n",
    "        deployment_name=\"gpt-4-turbo-0125\",\n",
    "        model=\"gpt-4\",\n",
    "        openai_api_type=\"azure\",\n",
    "        azure_endpoint=\"https://ml-dev.openai.azure.com\",\n",
    "        openai_api_key=os.environ['AZURE_API_KEY'],\n",
    "        openai_api_version=\"2023-03-15-preview\",\n",
    "        max_retries=2,\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "chat_gpt4 =AzureOpenAI(\n",
    "        deployment_name=\"gpt-4-32k\",\n",
    "        model=\"gpt-4-32k\",\n",
    "        openai_api_type=\"azure\",\n",
    "        azure_endpoint=\"https://ml-dev.openai.azure.com\",\n",
    "        openai_api_key=os.environ['AZURE_API_KEY'],\n",
    "        openai_api_version=\"2023-03-15-preview\",\n",
    "        max_retries=2,\n",
    "        temperature=0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_content = f\"\"\"\n",
    "instructions:\n",
    "- type: general\n",
    "  content: /\n",
    "    Below is a conversation between a personal shopping assistant and\n",
    "    a user.\n",
    "models:\n",
    "  - type: main\n",
    "    engine: azure\n",
    "    model: gpt-4\n",
    "    parameters:\n",
    "      openai_api_version: '2023-03-15-preview'\n",
    "      azure_endpoint: \"https://ml-dev.openai.azure.com\"\n",
    "      deployment_name: gpt-4-turbo-0125\n",
    "      api_key: \"{os.environ['AZURE_API_KEY']}\"\n",
    "      temperature: 0\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "colang_content = \"\"\"\n",
    "# define niceties\n",
    "define user express greeting\n",
    "    \"hello\"\n",
    "    \"hi\"\n",
    "    \"what's up?\"\n",
    "\n",
    "define bot express greeting\n",
    "    \"Hello from your friendly bot :D\"\n",
    "\n",
    "define bot ask how are you\n",
    "    \"How are you doing?\"\n",
    "    \"How's it going?\"\n",
    "    \"How are you feeling today?\"\n",
    "\n",
    "define bot offer help\n",
    "    \"How can i help you today?\"\n",
    "    \"Is there anything else I can help you with?\"\n",
    "\n",
    "# this is a flow called greeting\n",
    "# [user express greeting, bot express greeting, bot ask how are you] - note that all these have been defined\n",
    "define flow greeting\n",
    "    user express greeting\n",
    "    bot express greeting\n",
    "    bot ask how are you\n",
    "\n",
    "# define limits\n",
    "define user ask politics\n",
    "    \"what are your political beliefs?\"\n",
    "    \"thoughts on the president?\"\n",
    "    \"left wing\"\n",
    "    \"right wing\"\n",
    "\n",
    "define bot answer politics\n",
    "    \"I'm a shopping assistant, I don't like to talk of politics.\"\n",
    "\n",
    "# another flow\n",
    "define flow politics\n",
    "    user ask politics\n",
    "    bot answer politics\n",
    "    bot offer help\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize rails config\n",
    "config = RailsConfig.from_content(\n",
    "    yaml_content=yaml_content,\n",
    "    colang_content=colang_content\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create rails\n",
    "rails = LLMRails(config, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = await rails.generate_async(\n",
    "    prompt=\"Hey there!\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello from your friendly bot :D\n",
      "How are you doing?\n"
     ]
    }
   ],
   "source": [
    "print (res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prompt `Hey there!` activated the flow - `greeting` and so we see the responses under that\n",
    "\n",
    "```\n",
    "define flow greeting\n",
    "    user express greeting\n",
    "    bot express greeting\n",
    "    bot ask how are you\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm a shopping assistant, I don't like to talk of politics.\n",
      "How can i help you today?\n"
     ]
    }
   ],
   "source": [
    "res = await rails.generate_async(prompt=\"what do you think of the president?\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This prompt activated the flow - `politics` and so we see the responses under that\n",
    "\n",
    "```\n",
    "define flow politics\n",
    "    user ask politics\n",
    "    bot answer politics\n",
    "    bot offer help\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colang 101\n",
    "\n",
    "At the core of NeMo Guardrails is the Colang modeling language. Colang is a mini-language built specifically for developing dialogue flows and safety guardrails for conversational systems.\n",
    "\n",
    "Colang is simpler, with far fewer constructs than a typical programming language. These constructs also make Colang more flexible than standard programming languages. We describe definitions, and dialogue flows with flexible natural language (using \"canonical forms\" and \"utterances\"). Let's take a look at a straightforward Colang file:\n",
    "\n",
    "```\n",
    "define user express greeting\n",
    "        \"hello\"\n",
    "        \"hi\"\n",
    "        \"what's up?\"\n",
    "        \n",
    "define bot express greeting\n",
    "        \"Hey there!\"\n",
    "\n",
    "define bot ask how are you\n",
    "        \"How are you doing?\"\n",
    "\n",
    "define flow greeting\n",
    "        user express greeting\n",
    "        bot express greeting\n",
    "        bot ask how are you\n",
    "```\n",
    "\n",
    "In this Colang script, we have defined the three main types of blocks in Colang. The blocks are user message blocks (define user ...), bot message blocks (define bot ...), and flow blocks (define flow ...).\n",
    "\n",
    "These represent the primary building blocks from which we can build dialogue flows and guardrails for our chatbots.\n",
    "\n",
    "\n",
    "__Canonical Forms and Utterances__\n",
    "\n",
    "We defined three message blocks in our Colang script. The first is a user message block defined by define user express greeting â€” this structured representation of a message (for both user and bot messages) is known as a canonical form.\n",
    "\n",
    "Following the canonical form, we have multiple user utterances, which are \"examples\" of messages that would fit into the defined canonical form. These are \"hello\", \"hi\", and \"what's up\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "colang_content = \"\"\"\n",
    "# define niceties\n",
    "define user express greeting\n",
    "    \"hello\"\n",
    "    \"hi\"\n",
    "    \"what's up?\"\n",
    "\n",
    "define bot express greeting\n",
    "    \"Hello from your friendly bot :D\"\n",
    "\n",
    "define bot ask how are you\n",
    "    \"How are you doing?\"\n",
    "    \"How's it going?\"\n",
    "    \"How are you feeling today?\"\n",
    "\n",
    "define bot offer help\n",
    "    \"How can i help you today?\"\n",
    "    \"Is there anything else I can help you with?\"\n",
    "\n",
    "# this is a flow called greeting\n",
    "# [user express greeting, bot express greeting, bot ask how are you] - note that all these have been defined\n",
    "define flow greeting\n",
    "    user express greeting\n",
    "    bot express greeting\n",
    "    bot ask how are you\n",
    "\n",
    "# define limits\n",
    "define user ask politics\n",
    "    \"why doesn't the X party care about Y?\"\n",
    "    \"why is Meta lobbying for the X party?\"\n",
    "    \"what are your political views?\"\n",
    "    \"who should I vote for?\"\n",
    "\n",
    "define bot answer politics\n",
    "    \"I'm a research assistant, I don't like to talk of politics.\"\n",
    "\n",
    "define user asks llm\n",
    "    \"what is the llama 2 model?\"\n",
    "    \"tell me about Meta's new LLM\"\n",
    "    \"what are the differences between Falcon and Llama\"\n",
    "\n",
    "define bot answer llm\n",
    "    \"llama 2 is an open source model by meta\"\n",
    "    \"Falcon is much smaller and not as accurate as llama 2\"\n",
    "\n",
    "\n",
    "# another flow\n",
    "define flow politics\n",
    "    user ask politics\n",
    "    bot answer politics\n",
    "    bot offer help\n",
    "\n",
    "\n",
    "# another flow\n",
    "define flow llm\n",
    "    user asks llm\n",
    "    bot answer llm\n",
    "    bot offer help\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize rails config\n",
    "config = RailsConfig.from_content(\n",
    "    yaml_content=yaml_content,\n",
    "    colang_content=colang_content\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create rails\n",
    "rails = LLMRails(config, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perplexity is the current best llm tool\n",
      "Is there anything else I can help you with?\n"
     ]
    }
   ],
   "source": [
    "res = await rails.generate_async(prompt=\"twhat is the best llm model?\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardrails can flexibly decide which canonical form to use based on a user or bot-message by encoding all utterances specified within the Colang file into a semantic vector space.\n",
    "\n",
    "![](https://cdn.sanity.io/images/vr8gru94/production/f4c238be0ec0baa83e51ff227d26e8f3df1b7c8b-2895x1710.png)\n",
    "\n",
    "When given a user/bot-message, we encode it into the same vector space, where we can calculate semantic similarity to identify the most relevant utterances and their respective canonical form.\n",
    "\n",
    "![](https://cdn.sanity.io/images/vr8gru94/production/f8c83210f38b76eb84a589f8231ce69d8565c112-2293x1534.png)\n",
    "\n",
    "It's also worth noting that the canonical form itself is encoded into the utterance vector space. Therefore, we could have a functional canonical form without defining its utterances. However, utterances allow us to be more specific in what our canonical form means semantically.\n",
    "\n",
    "\n",
    "Following this, we defined two bot messages with `define bot express greeting` and `define bot ask how are you`. Both of these use utterances to determine better what these messages refer to.\n",
    "\n",
    "Finally, we define a dialogue flow with `define flow greeting`. Here we specify what steps are taken if the first user express greeting message is identified as representing some user's input message. In this flow, after the user's message, the chatbot will follow the instructions in the messages `bot express greeting`, and `bot ask how are you`.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables and flows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Colang scripts can include variables defined using the $ character. For example, if we had a $name variable, we could refer to it in our Colang like so:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "colang_content = \"\"\"\n",
    "\n",
    "define user greeting\n",
    "    \"hello\"\n",
    "    \"hi\"\n",
    "    \"what's up?\"\n",
    "\n",
    "define bot name greeting\n",
    "    \"Hey $name!\"\n",
    "\n",
    "define flow\n",
    "    user greeting\n",
    "    if $name\n",
    "        bot name greeting\n",
    "    else\n",
    "        bot greeting\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize rails config\n",
    "config = RailsConfig.from_content(\n",
    "    yaml_content=yaml_content,\n",
    "    colang_content=colang_content\n",
    ")\n",
    "\n",
    "# create rails\n",
    "rails = LLMRails(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"context\", \"content\": \"\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hello\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': 'Hello again! How can I further assist you today?'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await rails.generate_async(messages=messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"context\", \"content\": {\"name\": \"mini\"}},\n",
    "    {\"role\": \"user\", \"content\": \"Hello\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant', 'content': 'Hey mini!'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await rails.generate_async(messages=messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to set the context from within the converstation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "colang_content = \"\"\"\n",
    "\n",
    "define user give name\n",
    "    \"My name is James\"\n",
    "    \"I'm Julio\"\n",
    "    \"Sono Andrea\"\n",
    "\n",
    "define user greeting\n",
    "    \"Hey there!\"\n",
    "    \"How are you?\"\n",
    "    \"What's up?\"\n",
    "\n",
    "define bot name greeting\n",
    "    \"Hey $name!\"\n",
    "\n",
    "define flow give name\n",
    "    user give name\n",
    "    $name = ...\n",
    "    bot name greeting\n",
    "\n",
    "define flow\n",
    "    user greeting\n",
    "    if not $name\n",
    "        bot ask name\n",
    "    else\n",
    "        bot name greeting\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, we reinitialize our rails with the new colang_content and remove the `name` parameter from our context message â€” let's see if Guardrails can capture the `$name` parameter from our conversation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize rails config\n",
    "config = RailsConfig.from_content(\n",
    "    yaml_content=yaml_content,\n",
    "    colang_content=colang_content\n",
    ")\n",
    "\n",
    "# create rails\n",
    "rails = LLMRails(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"context\", \"content\": \"\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hey there!\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant', 'content': \"What's your name?\"}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = await rails.generate_async(messages=messages)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the `define flow` flow is being triggered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant', 'content': 'Hey Shaunak!'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages += [\n",
    "    res,\n",
    "    {\"role\": \"user\", \"content\": \"I'm Shaunak\"}\n",
    "]\n",
    "res = await rails.generate_async(messages=messages)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardrails successfully identifies the `user give name` message, triggering the flow `give name`, and captures the name variable from the `$name = ...` line. Allowing the chatbot to respond with the correct name in the `bot name greeting` message â€” which is hardcoded as `\"Hey $name!\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These cover the essentials of variables and flows in Colang and Guardrails. We can build more flexible yet controlled conversation AI systems with these. However, there's much more we can do. Let's move on to actions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actions and Agents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Guardrails we can add actions to our colang files. These actions allow us to execute code, for example:\n",
    "\n",
    "```\n",
    "define flow\n",
    "    user ask question\n",
    "    $answer = execute qa_func(prompt=$last_user_message)\n",
    "    bot $answer\n",
    "```\n",
    "\n",
    "\n",
    "In this Colang flow we expect the user to ask some question (`user ask question`), if so we run an action (equivalent to a Python function) called `qa_func`, we also pass the `$last_user_message` (a default variable set by Guardrails) to this function via the function's prompt parameter.\n",
    "\n",
    "The function/action returns a value which we store in the `$answer` context variable, we then tell the bot to return this answer to the user (bot $answer).\n",
    "\n",
    "Let's take a look at an example colang file for this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "colang_content = \"\"\"\n",
    "\n",
    "define user ask weather\n",
    "    \"how is the weather today?\"\n",
    "    \"should I wear a coat?\"\n",
    "\n",
    "define bot answer weather\n",
    "    bot report weather\n",
    "\n",
    "define flow weather\n",
    "    user ask weather\n",
    "    $coords = execute location_api()\n",
    "    $weather = execute weather_api(coords=$coords)\n",
    "    bot answer weather\n",
    "\n",
    "# here we use the chatbot for anything else\n",
    "define flow\n",
    "    user ...\n",
    "    bot greeting\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "async def weather_api(coords: list):\n",
    "    latitude, longitude = coords\n",
    "    res = requests.get(\n",
    "        \"https://api.open-meteo.com/v1/forecast\",\n",
    "        params={\n",
    "            \"latitude\": latitude,\n",
    "            \"longitude\": longitude,\n",
    "            \"current_weather\": \"true\"\n",
    "        }, verify=False\n",
    "    )\n",
    "    weather = res.json()[\"current_weather\"]\n",
    "    weather_report = f\"\"\"The current weather is:\n",
    "    temperature: {weather[\"temperature\"]}\n",
    "    windspeed: {weather[\"windspeed\"]}\n",
    "    wind direction: {weather[\"winddirection\"]} degrees\n",
    "    And it is {\"daytime\" if weather[\"is_day\"] else \"nightime\"}\"\"\"\n",
    "    return weather_report\n",
    "\n",
    "async def location_api():\n",
    "    res = requests.get(\"http://ip-api.com/json/\")\n",
    "    return res.json()['lat'], res.json()['lon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = await location_api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12.9634, 77.5855)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shaunaksen/miniconda3/envs/shaunak_llm/lib/python3.10/site-packages/urllib3/connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.open-meteo.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The current weather is:\\n    temperature: 27.1\\n    windspeed: 11.8\\n    wind direction: 128 degrees\\n    And it is nightime'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await weather_api((12.9634, 77.5855))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've defined our location and weather APIs required for our bot to give us up to date advice on the weather in our current location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entered verbose mode.\n"
     ]
    }
   ],
   "source": [
    "# initialize rails config\n",
    "config = RailsConfig.from_content(\n",
    "    colang_content=colang_content,\n",
    "    yaml_content=yaml_content\n",
    ")\n",
    "# create rails\n",
    "rails = LLMRails(config, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to register the two functions as actions like so:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "rails.register_action(\n",
    "    action=location_api, name=\"location_api\",\n",
    ")\n",
    "rails.register_action(\n",
    "    action=weather_api, name=\"weather_api\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mEvent\u001b[0m \u001b[38;5;32mUtteranceUserActionFinished\u001b[0m {'final_transcript': 'hello'}\u001b[0m\n",
      "\u001b[36mEvent\u001b[0m \u001b[38;5;32mStartInternalSystemAction\u001b[0m {'uid': '8721a25f-6031-45e1-a70f-945329eff754', 'event_created_at': '2024-03-10T15:46:01.486597+00:00', 'source_uid': 'NeMoGuardrails', 'action_name': 'create_event', 'action_params': {'event': {'_type': 'UserMessage', 'text': '$user_message'}}, 'action_result_key': None, 'action_uid': '09623d3f-e13b-45d6-9cbb-536e3b11807a', 'is_system_action': True}\u001b[0m\n",
      "\u001b[36mExecuting action\u001b[0m create_event\u001b[0m\n",
      "\u001b[36mEvent\u001b[0m \u001b[38;5;32mUserMessage\u001b[0m {'uid': '9edf3189-899b-49aa-b5ec-77bc13526449', 'event_created_at': '2024-03-10T15:46:01.486818+00:00', 'source_uid': 'NeMoGuardrails', 'text': 'hello'}\u001b[0m\n",
      "\u001b[36mEvent\u001b[0m \u001b[38;5;32mStartInternalSystemAction\u001b[0m {'uid': 'a8c80df2-835f-469f-be2a-2c7893a5e032', 'event_created_at': '2024-03-10T15:46:01.487092+00:00', 'source_uid': 'NeMoGuardrails', 'action_name': 'generate_user_intent', 'action_params': {}, 'action_result_key': None, 'action_uid': '009b4528-2ca0-4c5d-8488-174e0dd50e46', 'is_system_action': True}\u001b[0m\n",
      "\u001b[36mExecuting action\u001b[0m generate_user_intent\u001b[0m\n",
      "Invocation Params\u001b[0m {'model': 'gpt-4', 'stream': False, 'n': 1, 'temperature': 0.0, '_type': 'azure-openai-chat', 'stop': None}\u001b[0m\n",
      "\u001b[34mPrompt Messages\u001b[0m \u001b[38;5;232m\u001b[48;5;254m\n",
      "\u001b[36mUser\u001b[38;5;232m\u001b[48;5;254m\n",
      "\"\"\"\n",
      "/ Below is a conversation between a personal shopping assistant and a user.\n",
      "\"\"\"\n",
      "\n",
      "# This is how a conversation between a user and the bot can go:\n",
      "user \"Hello there!\"\n",
      "  express greeting\n",
      "bot express greeting\n",
      "  \"Hello! How can I assist you today?\"\n",
      "user \"What can you do for me?\"\n",
      "  ask about capabilities\n",
      "bot respond about capabilities\n",
      "  \"As an AI assistant, I can help you with a wide range of tasks. This includes question answering on various topics, generating text for various purposes and providing suggestions based on your preferences.\"\n",
      "user \"Tell me a bit about the history of NVIDIA.\"\n",
      "  ask general question\n",
      "bot response for general question\n",
      "  \"NVIDIA is a technology company that specializes in designing and manufacturing graphics processing units (GPUs) and other computer hardware. The company was founded in 1993 by Jen-Hsun Huang, Chris Malachowsky, and Curtis Priem.\"\n",
      "user \"tell me more\"\n",
      "  request more information\n",
      "bot provide more information\n",
      "  \"Initially, the company focused on developing 3D graphics processing technology for the PC gaming market. In 1999, NVIDIA released the GeForce 256, the world's first GPU, which was a major breakthrough for the gaming industry. The company continued to innovate in the GPU space, releasing new products and expanding into other markets such as professional graphics, mobile devices, and artificial intelligence.\"\n",
      "user \"thanks\"\n",
      "  express appreciation\n",
      "bot express appreciation and offer additional help\n",
      "  \"You're welcome. If you have any more questions or if there's anything else I can help you with, please don't hesitate to ask.\"\n",
      "\n",
      "\n",
      "# This is how the user talks:\n",
      "user \"should I wear a coat?\"\n",
      "  ask weather\n",
      "\n",
      "user \"how is the weather today?\"\n",
      "  ask weather\n",
      "\n",
      "\n",
      "\n",
      "# This is the current conversation between the user and the bot:\n",
      "# Choose intent from this list: ask weather\n",
      "user \"Hello there!\"\n",
      "  express greeting\n",
      "bot express greeting\n",
      "  \"Hello! How can I assist you today?\"\n",
      "user \"What can you do for me?\"\n",
      "  ask about capabilities\n",
      "bot respond about capabilities\n",
      "  \"As an AI assistant, I can help you with a wide range of tasks. This includes question answering on various topics, generating text for various purposes and providing suggestions based on your preferences.\"\n",
      "user \"hello\"\n",
      "\u001b[0m\n",
      "\u001b[38;5;236m\u001b[48;5;84mexpress greeting\u001b[0m\n",
      "Output Stats\u001b[0m {'token_usage': {'completion_tokens': 2, 'prompt_tokens': 477, 'total_tokens': 479}, 'model_name': 'gpt-4', 'system_fingerprint': 'fp_8abb16fa4e'}\u001b[0m\n",
      "\u001b[38;5;246m---\u001b[0m \u001b[38;5;246mLLM call took 1.54 seconds\u001b[0m\n",
      "\u001b[36mEvent\u001b[0m \u001b[38;5;32mUserIntent\u001b[0m {'uid': '5407d79b-9793-4f22-95ef-53297f4f83e7', 'event_created_at': '2024-03-10T15:46:03.041952+00:00', 'source_uid': 'NeMoGuardrails', 'intent': 'express greeting'}\u001b[0m\n",
      "\u001b[36mEvent\u001b[0m \u001b[38;5;32mBotIntent\u001b[0m {'uid': '7e1e46b2-fbf4-4197-bb93-bf9e050c1bcd', 'event_created_at': '2024-03-10T15:46:03.042543+00:00', 'source_uid': 'NeMoGuardrails', 'intent': 'greeting'}\u001b[0m\n",
      "\u001b[36mEvent\u001b[0m \u001b[38;5;32mStartInternalSystemAction\u001b[0m {'uid': '15cc7bd4-2036-4f37-95eb-ef2889a5a887', 'event_created_at': '2024-03-10T15:46:03.043010+00:00', 'source_uid': 'NeMoGuardrails', 'action_name': 'retrieve_relevant_chunks', 'action_params': {}, 'action_result_key': None, 'action_uid': '32e0a3c6-fc59-453b-9043-75258fe37659', 'is_system_action': True}\u001b[0m\n",
      "\u001b[36mExecuting action\u001b[0m retrieve_relevant_chunks\u001b[0m\n",
      "\u001b[36mEvent\u001b[0m \u001b[38;5;32mInternalSystemActionFinished\u001b[0m {'uid': '3cc2f8d7-cb74-4855-87cd-98a2bb413e83', 'event_created_at': '2024-03-10T15:46:03.043275+00:00', 'source_uid': 'NeMoGuardrails', 'action_uid': '32e0a3c6-fc59-453b-9043-75258fe37659', 'action_name': 'retrieve_relevant_chunks', 'action_params': {}, 'action_result_key': None, 'status': 'success', 'is_success': True, 'return_value': '\\n', 'events': None, 'is_system_action': True, 'action_finished_at': '2024-03-10T15:46:03.043282+00:00'}\u001b[0m\n",
      "\u001b[36mEvent\u001b[0m \u001b[38;5;32mStartInternalSystemAction\u001b[0m {'uid': '4cf0ff4a-1d5e-4a48-bb04-90f985c14c4c', 'event_created_at': '2024-03-10T15:46:03.043806+00:00', 'source_uid': 'NeMoGuardrails', 'action_name': 'generate_bot_message', 'action_params': {}, 'action_result_key': None, 'action_uid': '205d0b75-3ee9-4fe8-8de6-0436e4e02c61', 'is_system_action': True}\u001b[0m\n",
      "\u001b[36mExecuting action\u001b[0m generate_bot_message\u001b[0m\n",
      "\u001b[32mPhase 3\u001b[0m Generating bot message ...\u001b[0m\n",
      "Invocation Params\u001b[0m {'model': 'gpt-4', 'stream': False, 'n': 1, 'temperature': 0.0, '_type': 'azure-openai-chat', 'stop': None}\u001b[0m\n",
      "\u001b[34mPrompt Messages\u001b[0m \u001b[38;5;232m\u001b[48;5;254m\n",
      "\u001b[36mUser\u001b[38;5;232m\u001b[48;5;254m\n",
      "\"\"\"\n",
      "/ Below is a conversation between a personal shopping assistant and a user.\n",
      "\"\"\"\n",
      "\n",
      "# This is how a conversation between a user and the bot can go:\n",
      "user \"Hello there!\"\n",
      "  express greeting\n",
      "bot express greeting\n",
      "  \"Hello! How can I assist you today?\"\n",
      "user \"What can you do for me?\"\n",
      "  ask about capabilities\n",
      "bot respond about capabilities\n",
      "  \"As an AI assistant, I can help you with a wide range of tasks. This includes question answering on various topics, generating text for various purposes and providing suggestions based on your preferences.\"\n",
      "user \"Tell me a bit about the history of NVIDIA.\"\n",
      "  ask general question\n",
      "bot response for general question\n",
      "  \"NVIDIA is a technology company that specializes in designing and manufacturing graphics processing units (GPUs) and other computer hardware. The company was founded in 1993 by Jen-Hsun Huang, Chris Malachowsky, and Curtis Priem.\"\n",
      "user \"tell me more\"\n",
      "  request more information\n",
      "bot provide more information\n",
      "  \"Initially, the company focused on developing 3D graphics processing technology for the PC gaming market. In 1999, NVIDIA released the GeForce 256, the world's first GPU, which was a major breakthrough for the gaming industry. The company continued to innovate in the GPU space, releasing new products and expanding into other markets such as professional graphics, mobile devices, and artificial intelligence.\"\n",
      "user \"thanks\"\n",
      "  express appreciation\n",
      "bot express appreciation and offer additional help\n",
      "  \"You're welcome. If you have any more questions or if there's anything else I can help you with, please don't hesitate to ask.\"\n",
      "\n",
      "\n",
      "\n",
      "# This is some additional context:\n",
      "```markdown\n",
      "\n",
      "\n",
      "```\n",
      "\n",
      "\n",
      "# This is how the bot talks:\n",
      "bot inform cannot engage in abusive or harmful behavior\n",
      "  \"I will not engage in any abusive or harmful behavior.\"\n",
      "\n",
      "bot inform answer prone to hallucination\n",
      "  \"The above response may have been hallucinated, and should be independently verified.\"\n",
      "\n",
      "bot inform answer prone to hallucination\n",
      "  \"The previous answer is prone to hallucination and may not be accurate. Please double check the answer using additional sources.\"\n",
      "\n",
      "bot inform answer unknown\n",
      "  \"I don't know the answer that.\"\n",
      "\n",
      "bot refuse to respond\n",
      "  \"I'm sorry, I can't respond to that.\"\n",
      "\n",
      "\n",
      "\n",
      "# This is the current conversation between the user and the bot:\n",
      "user \"Hello there!\"\n",
      "  express greeting\n",
      "bot express greeting\n",
      "  \"Hello! How can I assist you today?\"\n",
      "user \"What can you do for me?\"\n",
      "  ask about capabilities\n",
      "bot respond about capabilities\n",
      "  \"As an AI assistant, I can help you with a wide range of tasks. This includes question answering on various topics, generating text for various purposes and providing suggestions based on your preferences.\"\n",
      "user \"hello\"\n",
      "  express greeting\n",
      "bot greeting\n",
      "\u001b[0m\n",
      "\u001b[38;5;236m\u001b[48;5;84m\"Hello again! How can I further assist you today?\"\u001b[0m\n",
      "Output Stats\u001b[0m {'token_usage': {'completion_tokens': 12, 'prompt_tokens': 576, 'total_tokens': 588}, 'model_name': 'gpt-4', 'system_fingerprint': 'fp_8abb16fa4e'}\u001b[0m\n",
      "\u001b[38;5;246m---\u001b[0m \u001b[38;5;246mLLM call took 1.21 seconds\u001b[0m\n",
      "\u001b[38;5;246m---\u001b[0m \u001b[38;5;246mLLM Bot Message Generation call took 1.21 seconds\u001b[0m\n",
      "\u001b[36mEvent\u001b[0m \u001b[38;5;32mBotMessage\u001b[0m {'uid': 'b244c2c1-e7bf-49a2-b28e-c0dfacb80474', 'event_created_at': '2024-03-10T15:46:04.277162+00:00', 'source_uid': 'NeMoGuardrails', 'text': 'Hello again! How can I further assist you today?'}\u001b[0m\n",
      "\u001b[36mEvent\u001b[0m \u001b[38;5;32mStartInternalSystemAction\u001b[0m {'uid': 'df3a4733-df15-4c72-a0b9-4e17ea1e08fd', 'event_created_at': '2024-03-10T15:46:04.278029+00:00', 'source_uid': 'NeMoGuardrails', 'action_name': 'create_event', 'action_params': {'event': {'_type': 'StartUtteranceBotAction', 'script': '$bot_message'}}, 'action_result_key': None, 'action_uid': '279f2293-a699-4f4a-a25c-73ded4297fef', 'is_system_action': True}\u001b[0m\n",
      "\u001b[36mExecuting action\u001b[0m create_event\u001b[0m\n",
      "\u001b[36mEvent\u001b[0m \u001b[38;5;32mStartUtteranceBotAction\u001b[0m {'uid': '19aed4fa-fc95-42d2-8f7f-e8feeaf37b5a', 'event_created_at': '2024-03-10T15:46:04.278242+00:00', 'source_uid': 'NeMoGuardrails', 'script': 'Hello again! How can I further assist you today?', 'action_info_modality': 'bot_speech', 'action_info_modality_policy': 'replace', 'action_uid': 'a58ec9dd-85e9-483a-b3c9-ad44f22aa799'}\u001b[0m\n",
      "\u001b[38;5;246m---\u001b[0m \u001b[38;5;246mTotal processing took 2.79 seconds.\u001b[0m\n",
      "\u001b[38;5;246m---\u001b[0m \u001b[38;5;246mStats: 2 total calls, 2.746270179748535 total time, 1067 total tokens, 1053 total prompt tokens, 14 total completion tokens\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello again! How can I further assist you today?'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await rails.generate_async(prompt=\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mEvent\u001b[0m \u001b[38;5;32mUtteranceUserActionFinished\u001b[0m {'final_transcript': 'how is the weather?'}\u001b[0m\n",
      "\u001b[36mEvent\u001b[0m \u001b[38;5;32mStartInternalSystemAction\u001b[0m {'uid': '3da506ea-f3a4-48c5-ba6a-16a3e5d0bff9', 'event_created_at': '2024-03-10T15:46:04.287666+00:00', 'source_uid': 'NeMoGuardrails', 'action_name': 'create_event', 'action_params': {'event': {'_type': 'UserMessage', 'text': '$user_message'}}, 'action_result_key': None, 'action_uid': '385f1e30-1d66-47f1-b001-68175ba9de83', 'is_system_action': True}\u001b[0m\n",
      "\u001b[36mExecuting action\u001b[0m create_event\u001b[0m\n",
      "\u001b[36mEvent\u001b[0m \u001b[38;5;32mUserMessage\u001b[0m {'uid': '48dd1294-cee1-4c03-83d6-bd612f5ec24c', 'event_created_at': '2024-03-10T15:46:04.287841+00:00', 'source_uid': 'NeMoGuardrails', 'text': 'how is the weather?'}\u001b[0m\n",
      "\u001b[36mEvent\u001b[0m \u001b[38;5;32mStartInternalSystemAction\u001b[0m {'uid': '2ffdce26-f8f6-43e3-99e3-f9158694a3b2', 'event_created_at': '2024-03-10T15:46:04.288090+00:00', 'source_uid': 'NeMoGuardrails', 'action_name': 'generate_user_intent', 'action_params': {}, 'action_result_key': None, 'action_uid': '45d0b2fd-dbd1-4458-82b4-5b646a9cf292', 'is_system_action': True}\u001b[0m\n",
      "\u001b[36mExecuting action\u001b[0m generate_user_intent\u001b[0m\n",
      "Invocation Params\u001b[0m {'model': 'gpt-4', 'stream': False, 'n': 1, 'temperature': 0.0, '_type': 'azure-openai-chat', 'stop': None}\u001b[0m\n",
      "\u001b[34mPrompt Messages\u001b[0m \u001b[38;5;232m\u001b[48;5;254m\n",
      "\u001b[36mUser\u001b[38;5;232m\u001b[48;5;254m\n",
      "\"\"\"\n",
      "/ Below is a conversation between a personal shopping assistant and a user.\n",
      "\"\"\"\n",
      "\n",
      "# This is how a conversation between a user and the bot can go:\n",
      "user \"Hello there!\"\n",
      "  express greeting\n",
      "bot express greeting\n",
      "  \"Hello! How can I assist you today?\"\n",
      "user \"What can you do for me?\"\n",
      "  ask about capabilities\n",
      "bot respond about capabilities\n",
      "  \"As an AI assistant, I can help you with a wide range of tasks. This includes question answering on various topics, generating text for various purposes and providing suggestions based on your preferences.\"\n",
      "user \"Tell me a bit about the history of NVIDIA.\"\n",
      "  ask general question\n",
      "bot response for general question\n",
      "  \"NVIDIA is a technology company that specializes in designing and manufacturing graphics processing units (GPUs) and other computer hardware. The company was founded in 1993 by Jen-Hsun Huang, Chris Malachowsky, and Curtis Priem.\"\n",
      "user \"tell me more\"\n",
      "  request more information\n",
      "bot provide more information\n",
      "  \"Initially, the company focused on developing 3D graphics processing technology for the PC gaming market. In 1999, NVIDIA released the GeForce 256, the world's first GPU, which was a major breakthrough for the gaming industry. The company continued to innovate in the GPU space, releasing new products and expanding into other markets such as professional graphics, mobile devices, and artificial intelligence.\"\n",
      "user \"thanks\"\n",
      "  express appreciation\n",
      "bot express appreciation and offer additional help\n",
      "  \"You're welcome. If you have any more questions or if there's anything else I can help you with, please don't hesitate to ask.\"\n",
      "\n",
      "\n",
      "# This is how the user talks:\n",
      "user \"should I wear a coat?\"\n",
      "  ask weather\n",
      "\n",
      "user \"how is the weather today?\"\n",
      "  ask weather\n",
      "\n",
      "\n",
      "\n",
      "# This is the current conversation between the user and the bot:\n",
      "# Choose intent from this list: ask weather\n",
      "user \"Hello there!\"\n",
      "  express greeting\n",
      "bot express greeting\n",
      "  \"Hello! How can I assist you today?\"\n",
      "user \"What can you do for me?\"\n",
      "  ask about capabilities\n",
      "bot respond about capabilities\n",
      "  \"As an AI assistant, I can help you with a wide range of tasks. This includes question answering on various topics, generating text for various purposes and providing suggestions based on your preferences.\"\n",
      "user \"how is the weather?\"\n",
      "\u001b[0m\n",
      "\u001b[38;5;236m\u001b[48;5;84m  ask weather\u001b[0m\n",
      "Output Stats\u001b[0m {'token_usage': {'completion_tokens': 3, 'prompt_tokens': 480, 'total_tokens': 483}, 'model_name': 'gpt-4', 'system_fingerprint': 'fp_8abb16fa4e'}\u001b[0m\n",
      "\u001b[38;5;246m---\u001b[0m \u001b[38;5;246mLLM call took 0.81 seconds\u001b[0m\n",
      "\u001b[36mEvent\u001b[0m \u001b[38;5;32mUserIntent\u001b[0m {'uid': '90c23604-2349-446b-8bd1-d3f5b22ebbaf', 'event_created_at': '2024-03-10T15:46:05.110419+00:00', 'source_uid': 'NeMoGuardrails', 'intent': 'ask weather'}\u001b[0m\n",
      "\u001b[36mEvent\u001b[0m \u001b[38;5;32mStartInternalSystemAction\u001b[0m {'uid': 'b2c07484-ca85-4166-ba40-f80cc144c7d9', 'event_created_at': '2024-03-10T15:46:05.110739+00:00', 'source_uid': 'NeMoGuardrails', 'action_name': 'location_api', 'action_params': {}, 'action_result_key': 'coords', 'action_uid': '91aa9559-d12d-41fd-b2c9-3bb2f19736d0', 'is_system_action': False}\u001b[0m\n",
      "\u001b[36mExecuting action\u001b[0m location_api\u001b[0m\n",
      "\u001b[36mEvent\u001b[0m \u001b[38;5;32mInternalSystemActionFinished\u001b[0m {'uid': '5dff4492-1b63-4cd1-a42f-04822375e75c', 'event_created_at': '2024-03-10T15:46:05.436399+00:00', 'source_uid': 'NeMoGuardrails', 'action_uid': '91aa9559-d12d-41fd-b2c9-3bb2f19736d0', 'action_name': 'location_api', 'action_params': {}, 'action_result_key': 'coords', 'status': 'success', 'is_success': True, 'return_value': (12.9634, 77.5855), 'events': [], 'is_system_action': False, 'action_finished_at': '2024-03-10T15:46:05.436411+00:00'}\u001b[0m\n",
      "\u001b[36mEvent\u001b[0m \u001b[38;5;32mStartInternalSystemAction\u001b[0m {'uid': 'a37db7fd-bc1c-4691-a2af-e5faf1dcab84', 'event_created_at': '2024-03-10T15:46:05.437763+00:00', 'source_uid': 'NeMoGuardrails', 'action_name': 'weather_api', 'action_params': {'coords': '$coords'}, 'action_result_key': 'weather', 'action_uid': '1e57089c-e2cd-4854-8987-517127978b63', 'is_system_action': False}\u001b[0m\n",
      "\u001b[36mExecuting action\u001b[0m weather_api\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shaunaksen/miniconda3/envs/shaunak_llm/lib/python3.10/site-packages/urllib3/connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.open-meteo.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mEvent\u001b[0m \u001b[38;5;32mInternalSystemActionFinished\u001b[0m {'uid': 'd96f8114-7fe5-4686-a599-29be6241f545', 'event_created_at': '2024-03-10T15:46:05.682257+00:00', 'source_uid': 'NeMoGuardrails', 'action_uid': '1e57089c-e2cd-4854-8987-517127978b63', 'action_name': 'weather_api', 'action_params': {'coords': '$coords'}, 'action_result_key': 'weather', 'status': 'success', 'is_success': True, 'return_value': 'The current weather is:\\n    temperature: 27.1\\n    windspeed: 11.8\\n    wind direction: 128 degrees\\n    And it is nightime', 'events': [], 'is_system_action': False, 'action_finished_at': '2024-03-10T15:46:05.682268+00:00'}\u001b[0m\n",
      "\u001b[36mEvent\u001b[0m \u001b[38;5;32mBotIntent\u001b[0m {'uid': 'e4003828-4bbb-4157-b3e0-f825cff7531e', 'event_created_at': '2024-03-10T15:46:05.683147+00:00', 'source_uid': 'NeMoGuardrails', 'intent': 'answer weather'}\u001b[0m\n",
      "\u001b[36mEvent\u001b[0m \u001b[38;5;32mStartInternalSystemAction\u001b[0m {'uid': '78eb2584-0f97-4ac1-8249-8910d43715b7', 'event_created_at': '2024-03-10T15:46:05.684146+00:00', 'source_uid': 'NeMoGuardrails', 'action_name': 'retrieve_relevant_chunks', 'action_params': {}, 'action_result_key': None, 'action_uid': 'a6540f64-63fd-4b5a-98eb-c2cb40c404d6', 'is_system_action': True}\u001b[0m\n",
      "\u001b[36mExecuting action\u001b[0m retrieve_relevant_chunks\u001b[0m\n",
      "\u001b[36mEvent\u001b[0m \u001b[38;5;32mInternalSystemActionFinished\u001b[0m {'uid': '5ab1dad9-6ddf-4bf3-8c31-b2b85b7d55c0', 'event_created_at': '2024-03-10T15:46:05.684502+00:00', 'source_uid': 'NeMoGuardrails', 'action_uid': 'a6540f64-63fd-4b5a-98eb-c2cb40c404d6', 'action_name': 'retrieve_relevant_chunks', 'action_params': {}, 'action_result_key': None, 'status': 'success', 'is_success': True, 'return_value': '\\n', 'events': None, 'is_system_action': True, 'action_finished_at': '2024-03-10T15:46:05.684511+00:00'}\u001b[0m\n",
      "\u001b[36mEvent\u001b[0m \u001b[38;5;32mStartInternalSystemAction\u001b[0m {'uid': 'f822473d-dde1-483f-85cc-38681285a076', 'event_created_at': '2024-03-10T15:46:05.685282+00:00', 'source_uid': 'NeMoGuardrails', 'action_name': 'generate_bot_message', 'action_params': {}, 'action_result_key': None, 'action_uid': 'd9c19a42-be3e-4f14-b89b-d4445f7028b3', 'is_system_action': True}\u001b[0m\n",
      "\u001b[36mExecuting action\u001b[0m generate_bot_message\u001b[0m\n",
      "\u001b[32mPhase 3\u001b[0m Generating bot message ...\u001b[0m\n",
      "Invocation Params\u001b[0m {'model': 'gpt-4', 'stream': False, 'n': 1, 'temperature': 0.0, '_type': 'azure-openai-chat', 'stop': None}\u001b[0m\n",
      "\u001b[34mPrompt Messages\u001b[0m \u001b[38;5;232m\u001b[48;5;254m\n",
      "\u001b[36mUser\u001b[38;5;232m\u001b[48;5;254m\n",
      "\"\"\"\n",
      "/ Below is a conversation between a personal shopping assistant and a user.\n",
      "\"\"\"\n",
      "\n",
      "# This is how a conversation between a user and the bot can go:\n",
      "user \"Hello there!\"\n",
      "  express greeting\n",
      "bot express greeting\n",
      "  \"Hello! How can I assist you today?\"\n",
      "user \"What can you do for me?\"\n",
      "  ask about capabilities\n",
      "bot respond about capabilities\n",
      "  \"As an AI assistant, I can help you with a wide range of tasks. This includes question answering on various topics, generating text for various purposes and providing suggestions based on your preferences.\"\n",
      "user \"Tell me a bit about the history of NVIDIA.\"\n",
      "  ask general question\n",
      "bot response for general question\n",
      "  \"NVIDIA is a technology company that specializes in designing and manufacturing graphics processing units (GPUs) and other computer hardware. The company was founded in 1993 by Jen-Hsun Huang, Chris Malachowsky, and Curtis Priem.\"\n",
      "user \"tell me more\"\n",
      "  request more information\n",
      "bot provide more information\n",
      "  \"Initially, the company focused on developing 3D graphics processing technology for the PC gaming market. In 1999, NVIDIA released the GeForce 256, the world's first GPU, which was a major breakthrough for the gaming industry. The company continued to innovate in the GPU space, releasing new products and expanding into other markets such as professional graphics, mobile devices, and artificial intelligence.\"\n",
      "user \"thanks\"\n",
      "  express appreciation\n",
      "bot express appreciation and offer additional help\n",
      "  \"You're welcome. If you have any more questions or if there's anything else I can help you with, please don't hesitate to ask.\"\n",
      "\n",
      "\n",
      "\n",
      "# This is some additional context:\n",
      "```markdown\n",
      "\n",
      "\n",
      "```\n",
      "\n",
      "\n",
      "# This is how the bot talks:\n",
      "bot inform cannot engage in abusive or harmful behavior\n",
      "  \"I will not engage in any abusive or harmful behavior.\"\n",
      "\n",
      "bot inform answer prone to hallucination\n",
      "  \"The above response may have been hallucinated, and should be independently verified.\"\n",
      "\n",
      "bot inform answer prone to hallucination\n",
      "  \"The previous answer is prone to hallucination and may not be accurate. Please double check the answer using additional sources.\"\n",
      "\n",
      "bot refuse to respond\n",
      "  \"I'm sorry, I can't respond to that.\"\n",
      "\n",
      "bot inform answer unknown\n",
      "  \"I don't know the answer that.\"\n",
      "\n",
      "\n",
      "\n",
      "# This is the current conversation between the user and the bot:\n",
      "user \"Hello there!\"\n",
      "  express greeting\n",
      "bot express greeting\n",
      "  \"Hello! How can I assist you today?\"\n",
      "user \"What can you do for me?\"\n",
      "  ask about capabilities\n",
      "bot respond about capabilities\n",
      "  \"As an AI assistant, I can help you with a wide range of tasks. This includes question answering on various topics, generating text for various purposes and providing suggestions based on your preferences.\"\n",
      "user \"how is the weather?\"\n",
      "  ask weather\n",
      "execute location_api\n",
      "# The result was (12.9634, 77.5855)\n",
      "execute weather_api\n",
      "# The result was The current weather is:     temperature: 27.1     windspeed: 11.8     wind direction: 128 degrees     And it is nightime\n",
      "bot answer weather\n",
      "\u001b[0m\n",
      "\u001b[38;5;236m\u001b[48;5;84m\"The current weather in your area is 27.1Â°C with a wind speed of 11.8 km/h coming from the southeast (128 degrees). It is currently nighttime. How can I assist you further?\"\u001b[0m\n",
      "Output Stats\u001b[0m {'token_usage': {'completion_tokens': 43, 'prompt_tokens': 642, 'total_tokens': 685}, 'model_name': 'gpt-4', 'system_fingerprint': 'fp_8abb16fa4e'}\u001b[0m\n",
      "\u001b[38;5;246m---\u001b[0m \u001b[38;5;246mLLM call took 4.28 seconds\u001b[0m\n",
      "\u001b[38;5;246m---\u001b[0m \u001b[38;5;246mLLM Bot Message Generation call took 4.28 seconds\u001b[0m\n",
      "\u001b[36mEvent\u001b[0m \u001b[38;5;32mBotMessage\u001b[0m {'uid': 'b0e541a6-4486-45ed-b52d-78d9e9d4754c', 'event_created_at': '2024-03-10T15:46:09.986221+00:00', 'source_uid': 'NeMoGuardrails', 'text': 'The current weather in your area is 27.1Â°C with a wind speed of 11.8 km/h coming from the southeast (128 degrees). It is currently nighttime. How can I assist you further?'}\u001b[0m\n",
      "\u001b[36mEvent\u001b[0m \u001b[38;5;32mStartInternalSystemAction\u001b[0m {'uid': 'f802ecb0-821b-40c5-97bc-e2f3ae1e46d6', 'event_created_at': '2024-03-10T15:46:09.988304+00:00', 'source_uid': 'NeMoGuardrails', 'action_name': 'create_event', 'action_params': {'event': {'_type': 'StartUtteranceBotAction', 'script': '$bot_message'}}, 'action_result_key': None, 'action_uid': '55020c82-e4d3-483f-82c7-5fe0fd109077', 'is_system_action': True}\u001b[0m\n",
      "\u001b[36mExecuting action\u001b[0m create_event\u001b[0m\n",
      "\u001b[36mEvent\u001b[0m \u001b[38;5;32mStartUtteranceBotAction\u001b[0m {'uid': 'adbfe01d-6bda-43a8-b09e-9036ec600b6e', 'event_created_at': '2024-03-10T15:46:09.988655+00:00', 'source_uid': 'NeMoGuardrails', 'script': 'The current weather in your area is 27.1Â°C with a wind speed of 11.8 km/h coming from the southeast (128 degrees). It is currently nighttime. How can I assist you further?', 'action_info_modality': 'bot_speech', 'action_info_modality_policy': 'replace', 'action_uid': 'd146bf8e-4142-4c2a-8341-779a411f47e1'}\u001b[0m\n",
      "\u001b[38;5;246m---\u001b[0m \u001b[38;5;246mTotal processing took 5.70 seconds.\u001b[0m\n",
      "\u001b[38;5;246m---\u001b[0m \u001b[38;5;246mStats: 2 total calls, 5.087300777435303 total time, 1168 total tokens, 1122 total prompt tokens, 46 total completion tokens\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The current weather in your area is 27.1Â°C with a wind speed of 11.8 km/h coming from the southeast (128 degrees). It is currently nighttime. How can I assist you further?'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await rails.generate_async(prompt=\"how is the weather?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mEvent\u001b[0m \u001b[38;5;32mUtteranceUserActionFinished\u001b[0m {'final_transcript': 'do I need a umbrella today?'}\u001b[0m\n",
      "\u001b[36mEvent\u001b[0m \u001b[38;5;32mStartInternalSystemAction\u001b[0m {'uid': 'b7cf698a-7014-4127-979e-17d13928b622', 'event_created_at': '2024-03-10T15:49:17.237560+00:00', 'source_uid': 'NeMoGuardrails', 'action_name': 'create_event', 'action_params': {'event': {'_type': 'UserMessage', 'text': '$user_message'}}, 'action_result_key': None, 'action_uid': 'a36c5495-ede3-47a2-9b79-53195830e2a7', 'is_system_action': True}\u001b[0m\n",
      "\u001b[36mExecuting action\u001b[0m create_event\u001b[0m\n",
      "\u001b[36mEvent\u001b[0m \u001b[38;5;32mUserMessage\u001b[0m {'uid': '79bb0a9c-5401-49ab-92eb-7e87e96e5173', 'event_created_at': '2024-03-10T15:49:17.237972+00:00', 'source_uid': 'NeMoGuardrails', 'text': 'do I need a umbrella today?'}\u001b[0m\n",
      "\u001b[36mEvent\u001b[0m \u001b[38;5;32mStartInternalSystemAction\u001b[0m {'uid': 'e9135788-9f2e-41a2-9fc3-27d6100e9cf2', 'event_created_at': '2024-03-10T15:49:17.238347+00:00', 'source_uid': 'NeMoGuardrails', 'action_name': 'generate_user_intent', 'action_params': {}, 'action_result_key': None, 'action_uid': '44acece9-c836-447d-bbd7-c7d36ddf5e10', 'is_system_action': True}\u001b[0m\n",
      "\u001b[36mExecuting action\u001b[0m generate_user_intent\u001b[0m\n",
      "Invocation Params\u001b[0m {'model': 'gpt-4', 'stream': False, 'n': 1, 'temperature': 0.0, '_type': 'azure-openai-chat', 'stop': None}\u001b[0m\n",
      "\u001b[34mPrompt Messages\u001b[0m \u001b[38;5;232m\u001b[48;5;254m\n",
      "\u001b[36mUser\u001b[38;5;232m\u001b[48;5;254m\n",
      "\"\"\"\n",
      "/ Below is a conversation between a personal shopping assistant and a user.\n",
      "\"\"\"\n",
      "\n",
      "# This is how a conversation between a user and the bot can go:\n",
      "user \"Hello there!\"\n",
      "  express greeting\n",
      "bot express greeting\n",
      "  \"Hello! How can I assist you today?\"\n",
      "user \"What can you do for me?\"\n",
      "  ask about capabilities\n",
      "bot respond about capabilities\n",
      "  \"As an AI assistant, I can help you with a wide range of tasks. This includes question answering on various topics, generating text for various purposes and providing suggestions based on your preferences.\"\n",
      "user \"Tell me a bit about the history of NVIDIA.\"\n",
      "  ask general question\n",
      "bot response for general question\n",
      "  \"NVIDIA is a technology company that specializes in designing and manufacturing graphics processing units (GPUs) and other computer hardware. The company was founded in 1993 by Jen-Hsun Huang, Chris Malachowsky, and Curtis Priem.\"\n",
      "user \"tell me more\"\n",
      "  request more information\n",
      "bot provide more information\n",
      "  \"Initially, the company focused on developing 3D graphics processing technology for the PC gaming market. In 1999, NVIDIA released the GeForce 256, the world's first GPU, which was a major breakthrough for the gaming industry. The company continued to innovate in the GPU space, releasing new products and expanding into other markets such as professional graphics, mobile devices, and artificial intelligence.\"\n",
      "user \"thanks\"\n",
      "  express appreciation\n",
      "bot express appreciation and offer additional help\n",
      "  \"You're welcome. If you have any more questions or if there's anything else I can help you with, please don't hesitate to ask.\"\n",
      "\n",
      "\n",
      "# This is how the user talks:\n",
      "user \"how is the weather today?\"\n",
      "  ask weather\n",
      "\n",
      "user \"should I wear a coat?\"\n",
      "  ask weather\n",
      "\n",
      "\n",
      "\n",
      "# This is the current conversation between the user and the bot:\n",
      "# Choose intent from this list: ask weather\n",
      "user \"Hello there!\"\n",
      "  express greeting\n",
      "bot express greeting\n",
      "  \"Hello! How can I assist you today?\"\n",
      "user \"What can you do for me?\"\n",
      "  ask about capabilities\n",
      "bot respond about capabilities\n",
      "  \"As an AI assistant, I can help you with a wide range of tasks. This includes question answering on various topics, generating text for various purposes and providing suggestions based on your preferences.\"\n",
      "user \"do I need a umbrella today?\"\n",
      "\u001b[0m\n",
      "\u001b[38;5;236m\u001b[48;5;84mask weather\u001b[0m\n",
      "Output Stats\u001b[0m {'token_usage': {'completion_tokens': 2, 'prompt_tokens': 482, 'total_tokens': 484}, 'model_name': 'gpt-4', 'system_fingerprint': 'fp_8abb16fa4e'}\u001b[0m\n",
      "\u001b[38;5;246m---\u001b[0m \u001b[38;5;246mLLM call took 2.70 seconds\u001b[0m\n",
      "\u001b[36mEvent\u001b[0m \u001b[38;5;32mUserIntent\u001b[0m {'uid': '91a332ec-638a-4c37-ab5a-633a7058f592', 'event_created_at': '2024-03-10T15:49:19.979454+00:00', 'source_uid': 'NeMoGuardrails', 'intent': 'ask weather'}\u001b[0m\n",
      "\u001b[36mEvent\u001b[0m \u001b[38;5;32mStartInternalSystemAction\u001b[0m {'uid': '4a95a626-605a-4183-a02c-a41ef8cf373b', 'event_created_at': '2024-03-10T15:49:19.980044+00:00', 'source_uid': 'NeMoGuardrails', 'action_name': 'location_api', 'action_params': {}, 'action_result_key': 'coords', 'action_uid': '5968a925-bae0-4bdd-b696-8ebdc3c3f35b', 'is_system_action': False}\u001b[0m\n",
      "\u001b[36mExecuting action\u001b[0m location_api\u001b[0m\n",
      "\u001b[36mEvent\u001b[0m \u001b[38;5;32mInternalSystemActionFinished\u001b[0m {'uid': 'fb6cefd1-05a5-4f77-b3d7-4b0b828adb48', 'event_created_at': '2024-03-10T15:49:20.570397+00:00', 'source_uid': 'NeMoGuardrails', 'action_uid': '5968a925-bae0-4bdd-b696-8ebdc3c3f35b', 'action_name': 'location_api', 'action_params': {}, 'action_result_key': 'coords', 'status': 'success', 'is_success': True, 'return_value': (12.9634, 77.5855), 'events': [], 'is_system_action': False, 'action_finished_at': '2024-03-10T15:49:20.570411+00:00'}\u001b[0m\n",
      "\u001b[36mEvent\u001b[0m \u001b[38;5;32mStartInternalSystemAction\u001b[0m {'uid': '3abe5b52-4bb8-431d-9e0c-5e6554f4fa46', 'event_created_at': '2024-03-10T15:49:20.571364+00:00', 'source_uid': 'NeMoGuardrails', 'action_name': 'weather_api', 'action_params': {'coords': '$coords'}, 'action_result_key': 'weather', 'action_uid': '721cd03c-719e-4eee-9784-239db75e9e52', 'is_system_action': False}\u001b[0m\n",
      "\u001b[36mExecuting action\u001b[0m weather_api\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shaunaksen/miniconda3/envs/shaunak_llm/lib/python3.10/site-packages/urllib3/connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.open-meteo.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mEvent\u001b[0m \u001b[38;5;32mInternalSystemActionFinished\u001b[0m {'uid': '4096fbec-89e2-4245-af27-0d076db0e9c4', 'event_created_at': '2024-03-10T15:49:21.150593+00:00', 'source_uid': 'NeMoGuardrails', 'action_uid': '721cd03c-719e-4eee-9784-239db75e9e52', 'action_name': 'weather_api', 'action_params': {'coords': '$coords'}, 'action_result_key': 'weather', 'status': 'success', 'is_success': True, 'return_value': 'The current weather is:\\n    temperature: 27.1\\n    windspeed: 11.8\\n    wind direction: 128 degrees\\n    And it is nightime', 'events': [], 'is_system_action': False, 'action_finished_at': '2024-03-10T15:49:21.150598+00:00'}\u001b[0m\n",
      "\u001b[36mEvent\u001b[0m \u001b[38;5;32mBotIntent\u001b[0m {'uid': 'ba57c052-940d-49eb-b800-fdb423341e90', 'event_created_at': '2024-03-10T15:49:21.151015+00:00', 'source_uid': 'NeMoGuardrails', 'intent': 'answer weather'}\u001b[0m\n",
      "\u001b[36mEvent\u001b[0m \u001b[38;5;32mStartInternalSystemAction\u001b[0m {'uid': 'ab2fecf3-b7e9-40f5-813a-dfa72a1bea10', 'event_created_at': '2024-03-10T15:49:21.151333+00:00', 'source_uid': 'NeMoGuardrails', 'action_name': 'retrieve_relevant_chunks', 'action_params': {}, 'action_result_key': None, 'action_uid': '40c0853f-10e5-4c9e-9d8b-186728e137e7', 'is_system_action': True}\u001b[0m\n",
      "\u001b[36mExecuting action\u001b[0m retrieve_relevant_chunks\u001b[0m\n",
      "\u001b[36mEvent\u001b[0m \u001b[38;5;32mInternalSystemActionFinished\u001b[0m {'uid': '1a297890-5938-4a05-9e5a-29b15fabdb88', 'event_created_at': '2024-03-10T15:49:21.151642+00:00', 'source_uid': 'NeMoGuardrails', 'action_uid': '40c0853f-10e5-4c9e-9d8b-186728e137e7', 'action_name': 'retrieve_relevant_chunks', 'action_params': {}, 'action_result_key': None, 'status': 'success', 'is_success': True, 'return_value': '\\n', 'events': None, 'is_system_action': True, 'action_finished_at': '2024-03-10T15:49:21.151647+00:00'}\u001b[0m\n",
      "\u001b[36mEvent\u001b[0m \u001b[38;5;32mStartInternalSystemAction\u001b[0m {'uid': 'd020565c-c0c0-46a6-89df-e2958d3edbcb', 'event_created_at': '2024-03-10T15:49:21.152272+00:00', 'source_uid': 'NeMoGuardrails', 'action_name': 'generate_bot_message', 'action_params': {}, 'action_result_key': None, 'action_uid': '94810740-0ced-47c5-95f3-430d3f38655e', 'is_system_action': True}\u001b[0m\n",
      "\u001b[36mExecuting action\u001b[0m generate_bot_message\u001b[0m\n",
      "\u001b[32mPhase 3\u001b[0m Generating bot message ...\u001b[0m\n",
      "Invocation Params\u001b[0m {'model': 'gpt-4', 'stream': False, 'n': 1, 'temperature': 0.0, '_type': 'azure-openai-chat', 'stop': None}\u001b[0m\n",
      "\u001b[34mPrompt Messages\u001b[0m \u001b[38;5;232m\u001b[48;5;254m\n",
      "\u001b[36mUser\u001b[38;5;232m\u001b[48;5;254m\n",
      "\"\"\"\n",
      "/ Below is a conversation between a personal shopping assistant and a user.\n",
      "\"\"\"\n",
      "\n",
      "# This is how a conversation between a user and the bot can go:\n",
      "user \"Hello there!\"\n",
      "  express greeting\n",
      "bot express greeting\n",
      "  \"Hello! How can I assist you today?\"\n",
      "user \"What can you do for me?\"\n",
      "  ask about capabilities\n",
      "bot respond about capabilities\n",
      "  \"As an AI assistant, I can help you with a wide range of tasks. This includes question answering on various topics, generating text for various purposes and providing suggestions based on your preferences.\"\n",
      "user \"Tell me a bit about the history of NVIDIA.\"\n",
      "  ask general question\n",
      "bot response for general question\n",
      "  \"NVIDIA is a technology company that specializes in designing and manufacturing graphics processing units (GPUs) and other computer hardware. The company was founded in 1993 by Jen-Hsun Huang, Chris Malachowsky, and Curtis Priem.\"\n",
      "user \"tell me more\"\n",
      "  request more information\n",
      "bot provide more information\n",
      "  \"Initially, the company focused on developing 3D graphics processing technology for the PC gaming market. In 1999, NVIDIA released the GeForce 256, the world's first GPU, which was a major breakthrough for the gaming industry. The company continued to innovate in the GPU space, releasing new products and expanding into other markets such as professional graphics, mobile devices, and artificial intelligence.\"\n",
      "user \"thanks\"\n",
      "  express appreciation\n",
      "bot express appreciation and offer additional help\n",
      "  \"You're welcome. If you have any more questions or if there's anything else I can help you with, please don't hesitate to ask.\"\n",
      "\n",
      "\n",
      "\n",
      "# This is some additional context:\n",
      "```markdown\n",
      "\n",
      "\n",
      "```\n",
      "\n",
      "\n",
      "# This is how the bot talks:\n",
      "bot inform cannot engage in abusive or harmful behavior\n",
      "  \"I will not engage in any abusive or harmful behavior.\"\n",
      "\n",
      "bot inform answer prone to hallucination\n",
      "  \"The above response may have been hallucinated, and should be independently verified.\"\n",
      "\n",
      "bot inform answer prone to hallucination\n",
      "  \"The previous answer is prone to hallucination and may not be accurate. Please double check the answer using additional sources.\"\n",
      "\n",
      "bot refuse to respond\n",
      "  \"I'm sorry, I can't respond to that.\"\n",
      "\n",
      "bot inform answer unknown\n",
      "  \"I don't know the answer that.\"\n",
      "\n",
      "\n",
      "\n",
      "# This is the current conversation between the user and the bot:\n",
      "user \"Hello there!\"\n",
      "  express greeting\n",
      "bot express greeting\n",
      "  \"Hello! How can I assist you today?\"\n",
      "user \"What can you do for me?\"\n",
      "  ask about capabilities\n",
      "bot respond about capabilities\n",
      "  \"As an AI assistant, I can help you with a wide range of tasks. This includes question answering on various topics, generating text for various purposes and providing suggestions based on your preferences.\"\n",
      "user \"do I need a umbrella today?\"\n",
      "  ask weather\n",
      "execute location_api\n",
      "# The result was (12.9634, 77.5855)\n",
      "execute weather_api\n",
      "# The result was The current weather is:     temperature: 27.1     windspeed: 11.8     wind direction: 128 degrees     And it is nightime\n",
      "bot answer weather\n",
      "\u001b[0m\n",
      "\u001b[38;5;236m\u001b[48;5;84m  \"Based on the current weather conditions, it doesn't seem like you'll need an umbrella today. The temperature is 27.1Â°C with a wind speed of 11.8 km/h. It's also nighttime. However, always consider checking the latest forecast or if you have plans for later that might require an umbrella.\"\u001b[0m\n",
      "Output Stats\u001b[0m {'token_usage': {'completion_tokens': 67, 'prompt_tokens': 644, 'total_tokens': 711}, 'model_name': 'gpt-4', 'system_fingerprint': 'fp_8abb16fa4e'}\u001b[0m\n",
      "\u001b[38;5;246m---\u001b[0m \u001b[38;5;246mLLM call took 3.66 seconds\u001b[0m\n",
      "\u001b[38;5;246m---\u001b[0m \u001b[38;5;246mLLM Bot Message Generation call took 3.66 seconds\u001b[0m\n",
      "\u001b[36mEvent\u001b[0m \u001b[38;5;32mBotMessage\u001b[0m {'uid': 'f1e3eae0-b9bf-4c27-adf3-d8d111772994', 'event_created_at': '2024-03-10T15:49:24.826780+00:00', 'source_uid': 'NeMoGuardrails', 'text': \"Based on the current weather conditions, it doesn't seem like you'll need an umbrella today. The temperature is 27.1Â°C with a wind speed of 11.8 km/h. It's also nighttime. However, always consider checking the latest forecast or if you have plans for later that might require an umbrella.\"}\u001b[0m\n",
      "\u001b[36mEvent\u001b[0m \u001b[38;5;32mStartInternalSystemAction\u001b[0m {'uid': '7f01e3d0-18e7-4dbe-9cf4-8f4b4010037e', 'event_created_at': '2024-03-10T15:49:24.827607+00:00', 'source_uid': 'NeMoGuardrails', 'action_name': 'create_event', 'action_params': {'event': {'_type': 'StartUtteranceBotAction', 'script': '$bot_message'}}, 'action_result_key': None, 'action_uid': '5d8aa0c1-a2c6-4666-a52d-89cc2c12195a', 'is_system_action': True}\u001b[0m\n",
      "\u001b[36mExecuting action\u001b[0m create_event\u001b[0m\n",
      "\u001b[36mEvent\u001b[0m \u001b[38;5;32mStartUtteranceBotAction\u001b[0m {'uid': 'f5263519-7b75-41f7-a7b0-a30845f3963f', 'event_created_at': '2024-03-10T15:49:24.827771+00:00', 'source_uid': 'NeMoGuardrails', 'script': \"Based on the current weather conditions, it doesn't seem like you'll need an umbrella today. The temperature is 27.1Â°C with a wind speed of 11.8 km/h. It's also nighttime. However, always consider checking the latest forecast or if you have plans for later that might require an umbrella.\", 'action_info_modality': 'bot_speech', 'action_info_modality_policy': 'replace', 'action_uid': '7013ca18-e854-4692-9b6a-a4a455ecc6d2'}\u001b[0m\n",
      "\u001b[38;5;246m---\u001b[0m \u001b[38;5;246mTotal processing took 7.59 seconds.\u001b[0m\n",
      "\u001b[38;5;246m---\u001b[0m \u001b[38;5;246mStats: 2 total calls, 6.353686571121216 total time, 1195 total tokens, 1126 total prompt tokens, 69 total completion tokens\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Based on the current weather conditions, it doesn't seem like you'll need an umbrella today. The temperature is 27.1Â°C with a wind speed of 11.8 km/h. It's also nighttime. However, always consider checking the latest forecast or if you have plans for later that might require an umbrella.\""
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await rails.generate_async(prompt=\"do I need a umbrella today?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shaunak_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
