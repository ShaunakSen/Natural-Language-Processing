{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ActiveLoop Course - LangChain & Vector Databases in Production\n",
    "\n",
    "> https://learn.activeloop.ai/enrollments\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/shaunaksen/Documents/personal-projects/Natural-Language-Processing/LLM Concepts/mini_projects/chatgpt_clone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_wrap(text, width=100):\n",
    " \"\"\"\n",
    " Prints text wrapped to a set width.\n",
    "\n",
    " Args:\n",
    "   text: The text to wrap.\n",
    "   width: The maximum width of each line.\n",
    "\n",
    " Returns:\n",
    "   None\n",
    " \"\"\"\n",
    " words = text.split()\n",
    " current_line = \"\"\n",
    " for word in words:\n",
    "   if len(current_line) + len(word) + 1 > width:\n",
    "     print(current_line)\n",
    "     current_line = word\n",
    "   else:\n",
    "     current_line += \" \" + word\n",
    " if current_line:\n",
    "   print(current_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# models and embeddings\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.embeddings import AzureOpenAIEmbeddings\n",
    "\n",
    "# prompts and utils\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "\n",
    "# memory\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# chains\n",
    "from langchain.chains import LLMChain, ConversationChain, RetrievalQA\n",
    "\n",
    "# vectorstores\n",
    "from langchain.vectorstores import DeepLake, FAISS\n",
    "from langchain.vectorstores.chroma import Chroma\n",
    "\n",
    "# agents and tools\n",
    "from langchain.agents import initialize_agent, Tool, load_tools\n",
    "from langchain.agents import AgentType\n",
    "from langchain.utilities import GoogleSearchAPIWrapper\n",
    "\n",
    "from creds import AZURE_API_BASE, AZURE_API_KEY, AZURE_API_VERSION, ACTIVELOOP_TOKEN, GOOGLE_API_KEY, GOOGLE_CSE_ID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_models() -> list:\n",
    "    embeddings = AzureOpenAIEmbeddings(\n",
    "        deployment=\"text-embedding-ada-002\",\n",
    "        model=\"text-embedding-ada-002\",\n",
    "        openai_api_type='azure',\n",
    "        azure_endpoint=AZURE_API_BASE,\n",
    "        openai_api_key=AZURE_API_KEY,\n",
    "        openai_api_version=AZURE_API_VERSION,\n",
    "        chunk_size=1, max_retries=1e0 \n",
    "    )\n",
    "\n",
    "    llm_chat_gpt_4 = AzureChatOpenAI(deployment_name='gpt-4-32k',\n",
    "                          model='gpt-4-32k',\n",
    "                          openai_api_type='azure',\n",
    "                          azure_endpoint=AZURE_API_BASE,\n",
    "                          openai_api_key=AZURE_API_KEY,\n",
    "                          openai_api_version=AZURE_API_VERSION,\n",
    "                          max_retries=2,\n",
    "                          temperature=0,\n",
    "                          streaming=True\n",
    "                          )\n",
    "\n",
    "    llm_gpt_4 = AzureOpenAI(deployment_name='gpt-4-32k',\n",
    "                            model='gpt-4-32k',\n",
    "                            openai_api_type='azure',\n",
    "                            azure_endpoint=AZURE_API_BASE,\n",
    "                            openai_api_key=AZURE_API_KEY,\n",
    "                            openai_api_version=AZURE_API_VERSION,\n",
    "                            max_retries=2,\n",
    "                            temperature=0,\n",
    "                            streaming=True\n",
    "                            )\n",
    "    \n",
    "    llm_text_davinci = AzureOpenAI(deployment_name='text-davinci-003',\n",
    "                          model='text-davinci-003',\n",
    "                          openai_api_type='azure',\n",
    "                          azure_endpoint=AZURE_API_BASE,\n",
    "                          openai_api_key=AZURE_API_KEY,\n",
    "                          openai_api_version=AZURE_API_VERSION,\n",
    "                          max_retries=2,\n",
    "                          temperature=0.5)\n",
    "    \n",
    "    return [embeddings, llm_chat_gpt_4, llm_gpt_4, llm_text_davinci]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings, llm_chat_gpt_4, llm_gpt_4, llm_text_davinci = init_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Interval runs: Start with a warm-up jog for 5-10 minutes, then alternate between 1 minute of sprinting and 1 minute of jogging for 30 minutes. \n",
      "\n",
      "2. Hill sprints: Find a hill that is about 200-400 meters long. Warm up with a jog for 5-10 minutes, then sprint up the hill for 30 seconds, rest for 30 seconds, and repeat for 10 minutes. \n",
      "\n",
      "3. Plyometric exercises: Perform exercises such as jump squats, box jumps, and burpees for 30 minutes. \n",
      "\n",
      "4. Outdoor circuit: Create an outdoor circuit with exercises such as squats, lunges, push-ups, and jumping jacks. Perform each exercise for 1 minute and rest for 30 seconds between each exercise. Repeat the circuit 3-4 times. \n",
      "\n",
      "5. Swimming: Swim laps for 30 minutes in a pool or lake. \n",
      "\n",
      "6. Hiking: Go on a hike with some hills for 30-60 minutes. \n",
      "\n",
      "7. Cycling: Cycle outdoors for 30-60 minutes. \n",
      "\n",
      "8. Rowing: Use a rowing machine or go to a lake to row for 30-60 minutes.\n"
     ]
    }
   ],
   "source": [
    "text = \"Suggest a personalized workout routine for someone looking to improve cardiovascular endurance and prefers outdoor activities.\"\n",
    "print(llm_text_davinci(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Chains\n",
    "\n",
    "In LangChain, a chain is an end-to-end wrapper around multiple individual components, providing a way to accomplish a common use case by combining these components in a specific sequence. The most commonly used type of chain is the LLMChain, which consists of a PromptTemplate, a model (either an LLM or a ChatModel), and an optional output parser.\n",
    "\n",
    "The LLMChain works as follows:\n",
    "\n",
    "\n",
    "\n",
    "1. Takes (multiple) input variables.\n",
    "1. Uses the PromptTemplate to format the input variables into a prompt.\n",
    "2. Passes the formatted prompt to the model (LLM or ChatModel).\n",
    "3. If an output parser is provided, it uses the OutputParser to parse the output of the LLM into a final format.\n",
    "\n",
    "In the next example, we demonstrate how to create a chain that generates a possible name for a company that produces eco-friendly water bottles. By using LangChain's LLMChain, PromptTemplate, and OpenAIclasses, we can easily define our prompt, set the input variables, and generate creative outputs. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=['product', 'character'],\n",
    "    template=\"What is a good name for a company that makes {product}. Be {character} in your response?\"\n",
    ")\n",
    "\n",
    "chain = LLMChain(prompt=prompt, llm=llm_text_davinci, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWhat is a good name for a company that makes bamboo toothbrushes. Be like Chandler Bibg in your response?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " Bambooth Toothbrushes.\n"
     ]
    }
   ],
   "source": [
    "print_wrap(chain.run(product=\"bamboo toothbrushes\", character=\"like Chandler Bibg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Memory\n",
    "\n",
    "\n",
    "In LangChain, Memory refers to the mechanism that stores and manages the conversation history between a user and the AI. It helps maintain context and coherency throughout the interaction, enabling the AI to generate more relevant and accurate responses. Memory, such as ConversationBufferMemory, acts as a wrapper around ChatMessageHistory, extracting the messages and providing them to the chain for better context-aware generation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()\n",
    "conversation_chain = ConversationChain(\n",
    "    llm=llm_text_davinci,\n",
    "    verbose=True,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Tell me about yourself.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Tell me about yourself.\n",
      "AI:  Hi there! I'm an AI created to help people with their everyday tasks. I'm programmed to understand natural language and provide helpful information. I'm also equipped with a knowledge base that I can draw from to answer questions. So, what can I help you with?\n",
      "Human: What can you do?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Tell me about yourself.\n",
      "AI:  Hi there! I'm an AI created to help people with their everyday tasks. I'm programmed to understand natural language and provide helpful information. I'm also equipped with a knowledge base that I can draw from to answer questions. So, what can I help you with?\n",
      "Human: What can you do?\n",
      "AI:  I can help you with a variety of tasks. I can offer information on a wide range of topics, provide guidance on how to accomplish certain tasks, and even help you find resources that may be useful. I'm also able to provide personalized recommendations based on your preferences.\n",
      "Human: How can you help me with data analysis?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "memory=ConversationBufferMemory(chat_memory=ChatMessageHistory(messages=[HumanMessage(content='Tell me about yourself.'), AIMessage(content=\" Hi there! I'm an AI created to help people with their everyday tasks. I'm programmed to understand natural language and provide helpful information. I'm also equipped with a knowledge base that I can draw from to answer questions. So, what can I help you with?\"), HumanMessage(content='What can you do?'), AIMessage(content=\" I can help you with a variety of tasks. I can offer information on a wide range of topics, provide guidance on how to accomplish certain tasks, and even help you find resources that may be useful. I'm also able to provide personalized recommendations based on your preferences.\"), HumanMessage(content='How can you help me with data analysis?'), AIMessage(content=\" I can help you with data analysis by providing guidance on how to organize your data, interpret it, and draw meaningful insights from it. I'm also able to provide resources that can help you learn more about data analysis, such as tutorials and online courses.\")])) verbose=True llm=AzureOpenAI(client=<openai.resources.completions.Completions object at 0x12a549ac0>, async_client=<openai.resources.completions.AsyncCompletions object at 0x12a568f70>, model_name='text-davinci-003', temperature=0.5, openai_api_key='07e78955020c4bf4886c3e0afe5d3909', openai_proxy='', azure_endpoint='https://ml-dev-3.openai.azure.com/', deployment_name='text-davinci-003', openai_api_version='2023-03-15-preview', openai_api_type='azure')\n"
     ]
    }
   ],
   "source": [
    "# Start the conversation\n",
    "conversation_chain.predict(input=\"Tell me about yourself.\")\n",
    "\n",
    "# Continue the conversation\n",
    "conversation_chain.predict(input=\"What can you do?\")\n",
    "conversation_chain.predict(input=\"How can you help me with data analysis?\")\n",
    "\n",
    "# Display the conversation\n",
    "print(conversation_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Lake VectorStore\n",
    "\n",
    "Deep Lake provides storage for embeddings and their corresponding metadata in the context of LLM apps. It enables hybrid searches on these embeddings and their attributes for efficient data retrieval. It also integrates with LangChain, facilitating the development and deployment of applications.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our documents\n",
    "texts = [\n",
    "    \"Napoleon Bonaparte was born in 15 August 1769\",\n",
    "    \"Louis XIV was born in 5 September 1638\"\n",
    "]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.create_documents(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Napoleon Bonaparte was born in 15 August 1769'),\n",
       " Document(page_content='Louis XIV was born in 5 September 1638')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"ACTIVELOOP_TOKEN\"] = ACTIVELOOP_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Lake Dataset in hub://shaunaksen/langchain_course_from_zero_to_hero already exists, loading from the storage\n"
     ]
    }
   ],
   "source": [
    "# create Deep Lake dataset\n",
    "# TODO: use your organization id here. (by default, org id is your username)\n",
    "my_activeloop_org_id = ACTIVELOOP_TOKEN \n",
    "my_activeloop_dataset_name = \"langchain_course_from_zero_to_hero\"\n",
    "dataset_path = f\"hub://shaunaksen/langchain_course_from_zero_to_hero\"\n",
    "db = DeepLake(dataset_path=dataset_path, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 2 embeddings in 1 batches of size 2:: 100%|██████████| 1/1 [00:23<00:00, 23.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://shaunaksen/langchain_course_from_zero_to_hero', tensors=['embedding', 'ids', 'metadata', 'text'])\n",
      "\n",
      "  tensor     htype     shape      dtype  compression\n",
      "  -------   -------   -------    -------  ------- \n",
      " embedding  generic  (12, 1536)  float32   None   \n",
      "    ids      text     (12, 1)      str     None   \n",
      " metadata    json     (12, 1)      str     None   \n",
      "   text      text     (12, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['b1b5b5ca-a1c7-11ee-847c-527b27766e9a',\n",
       " 'b1b5b6ce-a1c7-11ee-847c-527b27766e9a']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add documents to our Deep Lake dataset\n",
    "db.add_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If so, you’ve just created your first Deep Lake dataset!\n",
    "\n",
    "Now, let's create a RetrievalQA chain:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()\n",
    "retriever_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm_text_davinci,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever = retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents import AgentType\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Retrieval QA System\",\n",
    "        func=retriever_chain.run,\n",
    "        description=\"Useful for answering questions.\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "agent = initialize_agent(\n",
    "\ttools,\n",
    "\tllm_text_davinci,\n",
    "\tagent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "\tverbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.run(\"When was Napoleone born?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_chain.invoke(\"When was Napoleone born?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_text = open(\"state_of_the_union.txt\", \"r\").read()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "texts = text_splitter.split_text(full_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and the Cabinet. Justices of the Supreme Court. My fellow Americans.  \\n\\nLast year COVID-19 kept us apart. This year we are finally together again. \\n\\nTonight, we meet as Democrats Republicans and Independents. But most importantly as Americans. \\n\\nWith a duty to one another to the American people to the Constitution. \\n\\nAnd with an unwavering resolve that freedom will always triumph over tyranny. \\n\\nSix days ago, Russia’s Vladimir Putin sought to shake the foundations of the free world thinking he could make it bend to his menacing ways. But he badly miscalculated. \\n\\nHe thought he could roll into Ukraine and the world would roll over. Instead he met a wall of strength he never imagined. \\n\\nHe met the Ukrainian people. \\n\\nFrom President Zelenskyy to every Ukrainian, their fearlessness, their courage, their determination, inspires the world.',\n",
       " 'Groups of citizens blocking tanks with their bodies. Everyone from students to retirees teachers turned soldiers defending their homeland. \\n\\nIn this struggle as President Zelenskyy said in his speech to the European Parliament “Light will win over darkness.” The Ukrainian Ambassador to the United States is here tonight. \\n\\nLet each of us here tonight in this Chamber send an unmistakable signal to Ukraine and to the world. \\n\\nPlease rise if you are able and show that, Yes, we the United States of America stand with the Ukrainian people. \\n\\nThroughout our history we’ve learned this lesson when dictators do not pay a price for their aggression they cause more chaos.   \\n\\nThey keep moving.   \\n\\nAnd the costs and the threats to America and the world keep rising.   \\n\\nThat’s why the NATO Alliance was created to secure peace and stability in Europe after World War 2. \\n\\nThe United States is a member along with 29 other nations. \\n\\nIt matters. American diplomacy matters. American resolve matters.',\n",
       " 'It matters. American diplomacy matters. American resolve matters. \\n\\nPutin’s latest attack on Ukraine was premeditated and unprovoked. \\n\\nHe rejected repeated efforts at diplomacy. \\n\\nHe thought the West and NATO wouldn’t respond. And he thought he could divide us at home. Putin was wrong. We were ready.  Here is what we did.   \\n\\nWe prepared extensively and carefully. \\n\\nWe spent months building a coalition of other freedom-loving nations from Europe and the Americas to Asia and Africa to confront Putin. \\n\\nI spent countless hours unifying our European allies. We shared with the world in advance what we knew Putin was planning and precisely how he would try to falsely justify his aggression.  \\n\\nWe countered Russia’s lies with truth.   \\n\\nAnd now that he has acted the free world is holding him accountable.']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Chroma.from_texts(texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n",
      "\n",
      "And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence. \n",
      "\n",
      "A former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since she’s been nominated, she’s received a broad range of support—from the Fraternal Order of Police to former judges appointed by Democrats and Republicans. \n",
      "\n",
      "And if we are to advance liberty and justice, we need to secure the Border and fix the immigration system. \n",
      "\n",
      "We can do both. At our border, we’ve installed new technology like cutting-edge scanners to better detect drug smuggling.  \n",
      "\n",
      "We’ve set up joint patrols with Mexico and Guatemala to catch more human traffickers.\n"
     ]
    }
   ],
   "source": [
    "retrieved_docs = retriever.invoke(\n",
    "    \"What did the president say about Ketanji Brown Jackson?\"\n",
    ")\n",
    "print(retrieved_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RetrievalQA Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_qa = RetrievalQA.from_chain_type(\n",
    "\tllm=llm_text_davinci,\n",
    "\tchain_type=\"stuff\",\n",
    "\tretriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" The president said that Ketanji Brown Jackson is one of our nation's top legal minds, a former top litigator in private practice, a former federal public defender, from a family of public school educators and police officers, and a consensus builder. Since she's been nominated, she's received a broad range of support from the Fraternal Order of Police to former judges appointed by Democrats and Republicans.\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_qa.run(\"What did the president say about Ketanji Brown Jackson?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent with RetrievalQA chain as a tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Retrieval QA System\",\n",
    "        func=retrieval_qa.run,\n",
    "        description=\"Useful for answering questions.\"\n",
    "    )\n",
    "]\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm_text_davinci,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find a source that has a statement from the president about Ketanji Brown Jackson.\n",
      "Action: Retrieval QA System\n",
      "Action Input: \"What did the president say about Ketanji Brown Jackson?\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m The president said that Ketanji Brown Jackson is one of our nation's top legal minds, a former top litigator in private practice, a former federal public defender, and from a family of public school educators and police officers. He also said that she is a consensus builder and has received a broad range of support from the Fraternal Order of Police to former judges appointed by Democrats and Republicans.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The president said that Ketanji Brown Jackson is one of our nation's top legal minds, a former top litigator in private practice, a former federal public defender, and from a family of public school educators and police officers. He also said that she is a consensus builder and has received a broad range of support from the Fraternal Order of Police to former judges appointed by Democrats and Republicans.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The president said that Ketanji Brown Jackson is one of our nation's top legal minds, a former top litigator in private practice, a former federal public defender, and from a family of public school educators and police officers. He also said that she is a consensus builder and has received a broad range of support from the Fraternal Order of Police to former judges appointed by Democrats and Republicans.\n"
     ]
    }
   ],
   "source": [
    "response = agent.run(\"What did the president say about Ketanji Brown Jackson?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Databases\n",
    "\n",
    " **Here's a breakdown of how a basic vector database works and why we need them:**\n",
    "\n",
    "**Key Concepts:**\n",
    "\n",
    "- **Vectors:** Numerical representations of data that capture its features and characteristics in a high-dimensional space.\n",
    "- **Embeddings:** The process of converting raw data (text, images, audio, etc.) into vectors using machine learning techniques.\n",
    "- **Approximate Nearest Neighbor (ANN) Search:** A technique for finding similar vectors efficiently without exhaustively comparing every pair.\n",
    "\n",
    "**How It Works:**\n",
    "\n",
    "1. **Data Embedding:**\n",
    "   - Raw data is transformed into vectors using pre-trained or custom-built embedding models.\n",
    "   - These vectors capture semantic relationships and patterns within the data.\n",
    "\n",
    "2. **Vector Indexing:**\n",
    "   - The vectors are indexed using specialized algorithms designed for ANN search.\n",
    "   - Common algorithms include:\n",
    "     - Product Quantization (PQ)\n",
    "     - Locality Sensitive Hashing (LSH)\n",
    "     - Hierarchical Navigable Small World (HNSW)\n",
    "\n",
    "3. **Querying and Retrieval:**\n",
    "   - When a query is made, its embedding is calculated.\n",
    "   - The database efficiently finds the nearest neighbors (most similar vectors) to the query vector using the ANN algorithms.\n",
    "   - The corresponding raw data associated with those vectors is retrieved and returned to the user.\n",
    "\n",
    "**Why We Need Vector Databases:**\n",
    "\n",
    "- **Unstructured Data Handling:** They excel at managing and querying unstructured data that traditional databases struggle with.\n",
    "- **Similarity Search:** They enable fast and accurate retrieval of similar items based on their semantic meaning, not just exact matches.\n",
    "- **Richer Context Understanding:** Vector representations capture deeper semantic relationships, facilitating more nuanced and contextual search results.\n",
    "- **Scalable AI Integration:** They integrate seamlessly with machine learning models, allowing for real-time analysis and decision-making based on vector data.\n",
    "\n",
    "**Common Use Cases:**\n",
    "\n",
    "- **Recommender Systems:** Suggesting similar products, movies, music, articles, etc.\n",
    "- **Image and Video Search:** Finding visually similar images or videos.\n",
    "- **Text Search and Semantic Analysis:** Semantic search, document clustering, sentiment analysis, chatbots, plagiarism detection.\n",
    "- **Facial Recognition:** Identifying similar faces or objects.\n",
    "- **Drug Discovery:** Identifying potential drug candidates based on molecular structure similarity.\n",
    "- **Fraud Detection:** Anomaly detection in financial transactions.\n",
    "- **Personalization:** Tailoring user experiences based on preferences and behavior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents in LangChain\n",
    "\n",
    "In LangChain, agents are high-level components that use language models (LLMs) to determine which actions to take and in what order. An action can either be using a tool and observing its output or returning it to the user. Tools are functions that perform specific duties, such as Google Search, database lookups, or Python REPL.\n",
    "\n",
    "Agents involve an LLM making decisions about which Actions to take, taking that Action, seeing an Observation, and repeating that until done.\n",
    "\n",
    "Several types of agents are available in LangChain:\n",
    "\n",
    "- The zero-shot-react-description agent uses the ReAct framework to decide which tool to employ based purely on the tool's description. It necessitates a description of each tool.\n",
    "- The react-docstore agent engages with a docstore through the ReAct framework. It needs two tools: a Search tool and a Lookup tool. The Search tool finds a document, and the Lookup tool searches for a term in the most recently discovered document.\n",
    "- The self-ask-with-search agent employs a single tool named Intermediate Answer, which is capable of looking up factual responses to queries. It is identical to the original self-ask with the search paper, where a Google search API was provided as the tool.\n",
    "- The conversational-react-description agent is designed for conversational situations. It uses the ReAct framework to select a tool and uses memory to remember past conversation interactions.\n",
    "\n",
    "In our example, the Agent will use the Google Search tool to look up recent information about the Mars rover and generates a response based on this information.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.environ[\"GOOGLE_CSE_ID\"] = GOOGLE_CSE_ID\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = GoogleSearchAPIWrapper()\n",
    "\n",
    "tool = Tool(\n",
    "    name=\"Google Search\",\n",
    "    description=\"Search Google for recent results.\",\n",
    "    func=search.run,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"1 Child's First Name. (Type or print). BARACK. CERTIFICATE OF LIVE BIRTH lb ... OBAMA, II. Day. 4. 6b. Island. Year. 5b. Hour. 1961 7:24 P.M.. Oahu. 6d. Is Place\\xa0... His last name, Obama, was derived from his Luo descent. Obama's parents met in ... First 100 days. Main article: First 100 days of Barack Obama's presidency. Apr 12, 2017 ... President Barack Obama's full name is Barack Hussein Obama. Does it mean that he is a Muslim? 202,116 Views. First Lady Michelle LaVaughn Robinson Obama is a lawyer, writer, and the wife of the 44th President, Barack Obama. She is the first African-American First\\xa0... Apr 2, 2018 ... BARACK : Barkat and Mubarak both are derived from it in Hindi and Urdu. Roughly meaning blessing, abundance etc. Husen or Hussein from which\\xa0... Jan 19, 2017 ... Hopeful parents named their sons for the first Black president, whose name is a variation of the Hebrew name Baruch, which means “blessed”\\xa0... The Middle East remained a key foreign policy challenge. ... Learn more about Barack Obama's spouse, Michelle Obama. President Barack Obama and First Lady\\xa0... Barack Hussein Obama II was born August 4, 1961, in Honolulu, Hawaii, to parents Barack H. Obama, Sr., and Stanley Ann Dunham. His parents divorced when he\\xa0... 36M Followers, 9 Following, 881 Posts - See Instagram photos and videos from Barack Obama (@barackobama) First up, here are the books I've enjoyed reading. If you're looking for a new book over the holidays, give one of them a try. And if you can, shop at an\\xa0...\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.run(\"Obama's first name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Tool`` object represents a specific capability or function the system can use. In this case, it's a tool for performing Google searches.\n",
    "\n",
    "It is initialized with three parameters:\n",
    "\n",
    "- name parameter: This is a string that serves as a unique identifier for the tool. In this case, the name of the tool is \"google-search.”\n",
    "- func parameter: This parameter is assigned the function that the tool will execute when called. In this case, it's the run method of the search object, which presumably performs a Google search.\n",
    "- description parameter: This is a string that briefly explains what the tool does. The description explains that this tool is helpful when you need to use Google to answer questions about current events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = GoogleSearchAPIWrapper()\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"google-search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to search google to answer questions about current events\"\n",
    "\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create an agent that uses our Google Search tool:\n",
    "\n",
    "- initialize_agent(): This function call creates and initializes an agent. An agent is a component that determines which actions to take based on user input. These actions can be using a tool, returning a response to the user, or something else.\n",
    "\n",
    "- tools:  represents the list of Tool objects that the agent can use.\n",
    "\n",
    "- agent=\"zero-shot-react-description\": The \"zero-shot-react-description\" type of an Agent uses the ReAct framework to decide which tool to use based only on the tool's description.\n",
    "\n",
    "- verbose=True: when set to True, it will cause the Agent to print more detailed information about what it's doing. This is useful for debugging and understanding what's happening under the hood.\n",
    "\n",
    "- max_iterations=6: sets a limit on the number of iterations the Agent can perform before stopping. It's a way of preventing the agent from running indefinitely in some cases, which may have unwanted monetary costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm_text_davinci,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    max_iterations=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out what the latest news is about the Mars rover.\n",
      "Action: google-search\n",
      "Action Input: \"Mars rover news\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mA new video rings in the rover's ninth year on Mars, letting viewers tour Curiosity's location on a Martian mountain. More. NASA's Curiosity Mars rover used its ... Apr 25, 2023 ... The fully robotic Zhurong, named after a mythical Chinese god of fire, was expected to have woken up in December after entering a planned sleep ... NASA's Mars 2020 Perseverance rover will look for signs of past microbial life, cache rock and soil samples, and prepare for future human exploration. Dec 15, 2021 ... These and other findings were presented today during a news briefing at the American Geophysical Union fall science meeting in New Orleans. Even ... NASA InSight Study Provides Clearest Look Ever at Martian Core ... A pair of quakes in 2021 sent seismic waves deep into the Red Planet's core, giving scientists ... Oct 19, 2022 ... ... Curiosity, visit: http://mars.nasa.gov/msl. Get the Latest JPL News. SUBSCRIBE TO THE NEWSLETTER. News Media Contact. Andrew Good. Jet ... NASA's real-time portal for Mars exploration, featuring the latest news, images, and discoveries from the Red Planet. Mars rover apparently retrieves first rock sample for return to Earth ... Latest CBS News Videos. More Latest CBS News Videos · 1223-wn-shamlian.jpg. Latest CBS ... Jul 19, 2023 ... So the team will be keeping their options open, ready to stop for anything that piques their curiosity. Get the Latest JPL News. SUBSCRIBE TO ... NASA's Curiosity rover sends \"postcard\" showing Mars during different times of the day. By Kerry Breen. June 15, 2023 / 9:17 AM EDT / CBS News.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: NASA's Curiosity rover has sent a \"postcard\" showing Mars during different times of the day and is preparing to stop for anything that piques its curiosity. It is also nine years into its mission and has recently used its instruments to study the core of Mars.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " NASA's Curiosity rover has sent a \"postcard\" showing Mars during different times of the day and is\n",
      "preparing to stop for anything that piques its curiosity. It is also nine years into its mission and\n",
      "has recently used its instruments to study the core of Mars.\n"
     ]
    }
   ],
   "source": [
    "response = agent.run(\"What's the latest news about the Mars rover?\")\n",
    "print_wrap(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiops_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
