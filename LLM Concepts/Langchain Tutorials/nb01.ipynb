{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Development with Large Language Models Tutorial – OpenAI, Langchain, Agents, Chroma\n",
    "\n",
    "> Notes on tutorial by freecodecamp: https://www.youtube.com/watch?v=xZDB1naRUlk\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "import tiktoken\n",
    "import openai\n",
    "import chainlit as cl\n",
    "from chatgpt_clone.creds import AZURE_API_BASE, AZURE_API_KEY, AZURE_API_VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "AZURE_API_KEY = getpass.getpass(\"Enter Azure API Key: \")\n",
    "AZURE_API_BASE = getpass.getpass(\"Enter Azure Base URL: \")\n",
    "AZURE_API_VERSION = getpass.getpass(\"Enter Azure API version: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. ChainLit ChatGPT Clone\n",
    "\n",
    "- see `LLM Concepts/Langchain Tutorials/chatgpt_clone`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Building a Doc QnA System\n",
    "\n",
    "![](https://imgur.com/5EL92Tx.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some experiments with `chromadb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-16 13:28:46 - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.\n"
     ]
    }
   ],
   "source": [
    "chroma_client = chromadb.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "collections = chroma_client.create_collection(name=\"my_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shaunaksen/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz: 100%|██████████| 79.3M/79.3M [01:18<00:00, 1.06MiB/s]\n"
     ]
    }
   ],
   "source": [
    "collections.add(\n",
    "    documents=[\"my name is mini\", \"I am 28 years old\", \"I like to eat paneer\"], # list of actual docs\n",
    "    metadatas=[{\"source\": \"name\"}, {\"source\": \"age\"}, {\"source\": \"food\"}], # metadata of each doc; one use case is we can o/p the source for each doc\n",
    "    ids=[\"id1\", \"id2\", \"id3\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Collection(name=my_collection)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = collections.query(\n",
    "    query_texts=[\"what is my favorite dish?\"],\n",
    "    n_results=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['id3']],\n",
       " 'distances': [[1.0386817455291748]],\n",
       " 'metadatas': [[{'source': 'food'}]],\n",
       " 'embeddings': None,\n",
       " 'documents': [['I like to eat paneer']]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chat based on pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shaunaksen/miniconda3/envs/shaunak_llm/lib/python3.10/site-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (3.6.25) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import  OpenAIEmbeddings\n",
    "from langchain.document_loaders import TextLoader, PyPDFLoader\n",
    "from langchain.vectorstores import  Chroma\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.chat_models import AzureChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(\n",
    "    deployment=\"text-embedding-ada-002\",\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    openai_api_type='azure',\n",
    "    openai_api_base=AZURE_API_BASE,\n",
    "    openai_api_key=AZURE_API_KEY,\n",
    "    openai_api_version=AZURE_API_VERSION,\n",
    "    chunk_size=1, max_retries=1e0 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chat_gpt_4 = AzureChatOpenAI(deployment_name='gpt-4-32k',\n",
    "                          model='gpt-4-32k',\n",
    "                          openai_api_type='azure',\n",
    "                          openai_api_base=AZURE_API_BASE,\n",
    "                          openai_api_key=AZURE_API_KEY,\n",
    "                          openai_api_version=AZURE_API_VERSION,\n",
    "                          max_retries=2,\n",
    "                          temperature=0,\n",
    "                          streaming=True\n",
    "                          )\n",
    "\n",
    "llm_gpt_4 = AzureOpenAI(deployment_name='gpt-4-32k',\n",
    "                          model='gpt-4-32k',\n",
    "                          openai_api_type='azure',\n",
    "                          openai_api_base=AZURE_API_BASE,\n",
    "                          openai_api_key=AZURE_API_KEY,\n",
    "                          openai_api_version=AZURE_API_VERSION,\n",
    "                          max_retries=2,\n",
    "                          temperature=0,\n",
    "                          streaming=True\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"/Users/shaunaksen/Downloads/AIOPs RCA - Company level analysis.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='AIOPs Root Cause Analysis Analysis and findings ', metadata={'source': '/Users/shaunaksen/Downloads/AIOPs RCA - Company level analysis.pdf', 'page': 0}),\n",
       " Document(page_content='Root Cause Analysis Workflow and Objectives \\n', metadata={'source': '/Users/shaunaksen/Downloads/AIOPs RCA - Company level analysis.pdf', 'page': 1}),\n",
       " Document(page_content='Alert details: Slack message \\n', metadata={'source': '/Users/shaunaksen/Downloads/AIOPs RCA - Company level analysis.pdf', 'page': 2}),\n",
       " Document(page_content='Finding the top companies which contribute to the alert -Company: 1077776  had significant contribution to total transactions, avg_tx_bytes, avg_rx_bytes \\n-Company: 7626333 also contributed significantly to tx_bytes \\n-No other company contributes significantly to the metrics \\n', metadata={'source': '/Users/shaunaksen/Downloads/AIOPs RCA - Company level analysis.pdf', 'page': 3}),\n",
       " Document(page_content='Finding the top companies which contribute to the alert \\n', metadata={'source': '/Users/shaunaksen/Downloads/AIOPs RCA - Company level analysis.pdf', 'page': 4}),\n",
       " Document(page_content='Analyzing the WoW trend for shortlisted companies \\n', metadata={'source': '/Users/shaunaksen/Downloads/AIOPs RCA - Company level analysis.pdf', 'page': 5}),\n",
       " Document(page_content='Identifying the company-smeid combinations \\n1. Most of the smeid-company affected involve the company 1077776 which \\nis expected given the WoW trend we saw \\n2. All anomalies involve the rx_bytes feature \\n3. There are a couple of anomalies for company 7626333 as well \\n4. When we looked at the Wow trend - avg so the metric got smoothed out \\n5. When we look at an smeid level - we can see that there is an anomaly for \\ncompany 7626333 on certain smeids \\n', metadata={'source': '/Users/shaunaksen/Downloads/AIOPs RCA - Company level analysis.pdf', 'page': 6})]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='AIOPs Root Cause Analysis Analysis and findings', metadata={'source': '/Users/shaunaksen/Downloads/AIOPs RCA - Company level analysis.pdf', 'page': 0}),\n",
       " Document(page_content='Root Cause Analysis Workflow and Objectives', metadata={'source': '/Users/shaunaksen/Downloads/AIOPs RCA - Company level analysis.pdf', 'page': 1}),\n",
       " Document(page_content='Alert details: Slack message', metadata={'source': '/Users/shaunaksen/Downloads/AIOPs RCA - Company level analysis.pdf', 'page': 2}),\n",
       " Document(page_content='Finding the top companies which contribute to the alert -Company: 1077776  had significant contribution to total transactions, avg_tx_bytes, avg_rx_bytes \\n-Company: 7626333 also contributed significantly to tx_bytes \\n-No other company contributes significantly to the metrics', metadata={'source': '/Users/shaunaksen/Downloads/AIOPs RCA - Company level analysis.pdf', 'page': 3}),\n",
       " Document(page_content='Finding the top companies which contribute to the alert', metadata={'source': '/Users/shaunaksen/Downloads/AIOPs RCA - Company level analysis.pdf', 'page': 4}),\n",
       " Document(page_content='Analyzing the WoW trend for shortlisted companies', metadata={'source': '/Users/shaunaksen/Downloads/AIOPs RCA - Company level analysis.pdf', 'page': 5}),\n",
       " Document(page_content='Identifying the company-smeid combinations \\n1. Most of the smeid-company affected involve the company 1077776 which \\nis expected given the WoW trend we saw \\n2. All anomalies involve the rx_bytes feature \\n3. There are a couple of anomalies for company 7626333 as well \\n4. When we looked at the Wow trend - avg so the metric got smoothed out \\n5. When we look at an smeid level - we can see that there is an anomaly for \\ncompany 7626333 on certain smeids', metadata={'source': '/Users/shaunaksen/Downloads/AIOPs RCA - Company level analysis.pdf', 'page': 6})]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-17 10:42:22 - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.\n"
     ]
    }
   ],
   "source": [
    "docsearch = Chroma.from_documents(\n",
    "    documents, embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "        llm_chat_gpt_4,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=docsearch.as_retriever(max_tokens_limit=4097),\n",
    "        verbose=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQAWithSourcesChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Which company id contributes most to the alert?',\n",
       " 'answer': 'Company 1077776 contributes most to the alert, with significant contributions to total transactions, avg_tx_bytes, and avg_rx_bytes.\\n',\n",
       " 'sources': '/Users/shaunaksen/Downloads/AIOPs RCA - Company level analysis.pdf'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain(\"Which company id contributes most to the alert?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shaunak_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
