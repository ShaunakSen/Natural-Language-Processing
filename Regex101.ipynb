{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Regex101.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN5xNBJK0bjmbkn2LLS9EyH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShaunakSen/Natural-Language-Processing/blob/master/Regex101.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSlvqrVIRIbc"
      },
      "source": [
        "## Regular Expressions - Basics to Advanced\n",
        "\n",
        "> https://web.stanford.edu/~jurafsky/slp3/\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fw03siuRSOuP"
      },
      "source": [
        "### The need for regular expressions\n",
        "\n",
        "Regular expressions can be used to specify strings we might want to\n",
        "extract from a document, , from transforming “I need X” in Eliza above, to defining strings like $199 or $24.99 for extracting tables of prices from a document.\n",
        "\n",
        "#### Text normalization\n",
        "\n",
        "Normalizing text means converting it to a more convenient, standard form.\n",
        "\n",
        "1. __Tokenization__\n",
        "\n",
        "For example, most of what we are going to\n",
        "do with language relies on first separating out or tokenizing words from running\n",
        "tokenization text, the task of tokenization. English words are often separated from each other by whitespace, but whitespace is not always sufficient. \"New York\" and \"rock ’n’ roll\" are sometimes treated as large words despite the fact that they contain spaces, while sometimes we’ll need to separate \"I’m\" into the two words I and am. For processing tweets or texts we’ll need to tokenize emoticons like :) or hashtags like #nlproc. Some languages, like Japanese, don’t have spaces between words, so word tokenization becomes more difficult.\n",
        "\n",
        "2. __Lemmitization__:\n",
        "\n",
        "Another part of text normalization is lemmatization, the task of determining\n",
        "that two words have the same root, despite their surface differences. For example, the words sang, sung, and sings are forms of the verb sing. The word sing is the common lemma of these words, and a lemmatizer maps from all of these to sing.\n",
        "\n",
        "Lemmatization is essential for processing morphologically complex languages like\n",
        "stemming Arabic\n",
        "\n",
        "3. __Stemming__:\n",
        "\n",
        "Stemming refers to a simpler version of lemmatization in which we mainly\n",
        "just strip suffixes from the end of the word.\n",
        "\n",
        "4. __Sentence segmentation__:\n",
        "\n",
        "Text normalization also includes sentence segmentation: breaking up a text into individual sentences, using cues like sentence\n",
        "segmentation periods or exclamation points.\n",
        "\n",
        "Finally, we’ll need to compare words and other strings. We’ll introduce a metric\n",
        "called __edit distance__ that measures how similar two strings are based on the number\n",
        "of edits (insertions, deletions, substitutions) it takes to change one string into the\n",
        "other. Edit distance is an algorithm with applications throughout language processing, from spelling correction to speech recognition to coreference resolution.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdrYWLXrUgpL"
      },
      "source": [
        "### Basic Regex\n",
        "\n",
        "The simplest kind of regular expression is a sequence of simple characters. To search for woodchuck, we type /woodchuck/. The expression /Buttercup/ matches any string containing the substring Buttercup; grep with that expression would return the line I’m called little Buttercup. The search string can consist of a single character (like /!/) or a sequence of characters (like /urgl/).\n",
        "\n",
        "Regular expressions are case sensitive; lower case /s/ is distinct from upper\n",
        "case /S/ (/s/ matches a lower case s but not an upper case S). This means that\n",
        "the pattern /woodchucks/ will not match the string Woodchucks. We can solve this\n",
        "problem with the use of the square braces [ and ]. The string of characters inside the braces specifies a disjunction of characters to match\n",
        "\n",
        "For example, Fig. 2.2 shows\n",
        "that the pattern /[wW]/ matches patterns containing either w or W.\n",
        "\n",
        "![](https://i.imgur.com/E8CRgco.png)\n",
        "\n",
        "The square braces can also be used to specify what a single character cannot be,\n",
        "by use of the caret ˆ. If the caret ˆ is the __first symbol after the open square brace__ [, the resulting pattern is negated. For example, the pattern /[ˆa]/ matches any single character (including special characters) except a. \n",
        "\n",
        "This is only true when the caret is the first symbol after the open square brace. If it occurs anywhere else, it usually\n",
        "stands for a caret;\n",
        "\n",
        "![](https://i.imgur.com/i3WuhN8.png)\n",
        "\n",
        "How can we talk about optional elements, like an optional 's' in woodchuck and\n",
        "woodchucks? We can’t use the square brackets, because while they allow us to say\n",
        "“s or S”, they don’t allow us to say “s or nothing”. For this we use the question mark\n",
        "/?/, which means “the preceding character or nothing”,\n",
        "\n",
        "We can think of the question mark as meaning “zero or one instances of the\n",
        "previous character”. That is, it’s a way of specifying how many of something that we want, something that is very important in regular expressions. For example, consider the language of certain sheep, which consists of strings that look like the\n",
        "following:\n",
        "\n",
        "baa!\n",
        "baaa!\n",
        "baaaa!\n",
        "baaaaa!\n",
        "\n",
        "One solution : `/ba+!/`\n",
        "\n",
        "+ matches the previous token between one and unlimited times\n",
        "\n",
        "Another approach: This language consists of strings with a b, followed by at least two a’s, followed by an exclamation point. The set of operators that allows us to say things like “some Kleene * number of as” are based on the asterisk or *\n",
        "\n",
        "The Kleene star means “zero or more occurrences\n",
        "of the immediately previous character or regular expression”. So `/a*/` means “any\n",
        "string of zero or more as”\n",
        "This will match a or aaaaaa, but it will also match Off\n",
        "Minor since the string Off Minor has zero a’s. So the regular expression for matching\n",
        "one or more a is `/aa*/`, meaning one a followed by zero or more a's\n",
        "\n",
        "More complex\n",
        "patterns can also be repeated. So /[ab]*/ means “zero or more a’s __or__ b’s” (not\n",
        "“zero or more right square braces”). This will match strings like aaaa or ababab or\n",
        "bbbb..\n",
        "\n",
        "![](https://i.imgur.com/YcQmUJu.png)\n",
        "\n",
        "Here we matched any char in a-z followed by a group of 0 or more a or b\n",
        "\n",
        "For specifying multiple digits (useful for finding prices) we can extend /[0-9],\n",
        "the regular expression for a single digit. An integer (a string of digits) is thus /[0-9][0-9]*/. (Why isn’t it just /[0-9]*/?)\n",
        "\n",
        "- because /[0-9]*/ matches 0 or more occurances so even if we have something like \"abcd\" it will return a match\n",
        "\n",
        "![](https://i.imgur.com/CyaFc2u.png)\n",
        "- no match\n",
        "\n",
        "![](https://i.imgur.com/Rb8Jk3w.png)\n",
        "\n",
        "Sometimes it’s annoying to have to write the regular expression for digits twice, so there is a shorter way to specify “at least one” of some character. This is the Kleene + Kleene +, which means “one or more occurrences of the immediately preceding character or regular expression”. Thus, the expression /[0-9]+/ is the normal way to specify “a sequence of digits”. There are thus two ways to specify the sheep language: /baaa*!/ or /baa+!/.\n",
        "\n",
        "\n",
        "One very important special character is the period (/./), a wildcard expression\n",
        "that matches any single character (except a carriage return)\n",
        "\n",
        "![](https://i.imgur.com/fv6jBVR.png)\n",
        "\n",
        "This basically matches \"aardvark\" followed by 0 or more occurance of any character followed by \"aardvark\" again\n",
        "\n",
        "![](https://i.imgur.com/zJFxTbM.png)\n",
        "\n",
        "\n",
        "Anchors are special characters that anchor regular expressions to particular places in a string. The most common anchors are the caret ˆ and the dollar sign $. The caret ˆ matches the start of a line. The pattern /ˆThe/ matches the word The only at the start of the line. Thus, the caret ˆ has three uses\n",
        "\n",
        "1. to match the start of a line\n",
        "2. to indicate a negation inside of square brackets\n",
        "3. just to mean a caret\n",
        "\n",
        "The dollar sign $ matches the end of a line. So the pattern [space]$ is a useful\n",
        "pattern for matching a space at the end of a line\n",
        "\n",
        "/ˆThe dog\\.$/ matches a line that contains only the phrase The dog. (We have to use the backslash here since we want the . to mean “period” and not the wildcard.)\n",
        "\n",
        "![](https://i.imgur.com/wptmdwu.png)\n",
        "\n",
        "In the below example\n",
        "\n",
        "^The -> matches The at start -> space -> dog -> 0 or more chars -> end with a \".\"\n",
        "\n",
        "![](https://i.imgur.com/UkIPQGN.png)\n",
        "\n",
        "![](https://i.imgur.com/pK3ONe2.png)\n",
        "\n",
        "![](https://i.imgur.com/m00sE3h.png)\n",
        "\n",
        "![](https://i.imgur.com/o5LryyM.png)\n",
        "\n",
        "Example of a word boundary only on one side:\n",
        "\n",
        "![](https://i.imgur.com/jV6mgrw.png)\n",
        "\n",
        "See how \"the\" in \"ther\" is matched as we only required a boundary on the LHS\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kv4McuhK-nqZ"
      },
      "source": [
        "### Disjunction, Grouping, and Precedence\n",
        "\n",
        "![](https://i.imgur.com/5bdTWJM.png)\n",
        "\n",
        "![](https://i.imgur.com/QnpLwCI.png)\n",
        "\n",
        "![](https://i.imgur.com/mk2r4w8.png)\n",
        "\n",
        "![](https://i.imgur.com/pXJXzID.png)\n",
        "\n",
        "![](https://i.imgur.com/kqdE3tS.png)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Greedy search:\n",
        "\n",
        "![](https://i.imgur.com/zp1re7Q.png)\n",
        "\n",
        "`* matches the previous token between zero and unlimited times, as many times as possible, giving back as needed (greedy)`\n",
        "\n",
        "\n",
        "\n",
        "Matches :\n",
        "\n",
        "```\n",
        "once\n",
        "[space]\n",
        "upon\n",
        "[space]\n",
        "a\n",
        "[space]\n",
        "time\n",
        "```\n",
        "\n",
        "`*? matches the previous token between zero and unlimited times, as few times as possible, expanding as needed (lazy)`\n",
        "\n",
        "Matches\n",
        "\n",
        "```\n",
        "\n",
        "o\n",
        "\n",
        "n\n",
        "\n",
        "c\n",
        "\n",
        "e\n",
        "\n",
        "\n",
        "u\n",
        "\n",
        "p\n",
        "\n",
        "o\n",
        "\n",
        "n\n",
        "\n",
        "\n",
        "a\n",
        "\n",
        "\n",
        "t\n",
        "\n",
        "i\n",
        "\n",
        "m\n",
        "\n",
        "e\n",
        "```\n",
        "\n",
        "\n",
        "`+? matches the previous token between one and unlimited times, as few times as possible, expanding as needed (lazy)`\n",
        "\n",
        "\n",
        "Matches:\n",
        "```\n",
        "o\n",
        "n\n",
        "c\n",
        "e\n",
        "u\n",
        "p\n",
        "o\n",
        "n\n",
        "a\n",
        "t\n",
        "i\n",
        "m\n",
        "e\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZeqP3FNORa6"
      },
      "source": [
        "### Simple examples\n",
        "\n",
        "Suppose we wanted to write a RE to find cases of the English article the. A simple soln:\n",
        "\n",
        "![](https://i.imgur.com/pH5tgsO.png)\n",
        "\n",
        "But we will still incorrectly return texts with the embedded in other words (e.g., other or theology). So we need to specify that we want instances with a word boundary on both sides:\n",
        "\n",
        "![](https://i.imgur.com/FNVlldf.png)\n",
        "\n",
        "\n",
        "![](https://i.imgur.com/IS8tY5c.png)\n",
        "\n",
        "Suppose we wanted to do this without the use of /\\b/. We might want this since\n",
        "/\\b/ won’t treat underscores and numbers as word boundaries; but we might want\n",
        "to find the in some context where it might also have underlines or numbers nearby\n",
        "(the_ or the25). We need to specify that we want instances in which there are no\n",
        "alphabetic letters on either side of the the:\n",
        "\n",
        "![](https://i.imgur.com/9ZWmwNp.png)\n",
        "\n",
        "\n",
        "![](https://i.imgur.com/vs2JNfV.png)\n",
        "\n",
        "![](https://i.imgur.com/dgomS6F.png)\n",
        "\n",
        "\n",
        "![](https://i.imgur.com/8sY5DbN.png)\n",
        "\n",
        "The process we just went through was based on fixing two kinds of errors: false\n",
        "false positives positives, strings that we incorrectly matched like other or there, and false negafalse negatives tives, strings that we incorrectly missed, like The. Addressing these two kinds of\n",
        "errors comes up again and again in implementing speech and language processing\n",
        "systems\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUmOcOz-7iWT"
      },
      "source": [
        "### More operrators\n",
        "\n",
        "![](https://i.imgur.com/bzFoBPO.png)\n",
        "\n",
        "![](https://i.imgur.com/jtQbqLq.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZIaSbZrA1RZ"
      },
      "source": [
        "### A More Complex Example\n",
        "\n",
        "Let’s try out a more significant example of the power of REs. Suppose we want to\n",
        "build an application to help a user buy a computer on the Web. The user might want\n",
        "“any machine with at least 6 GHz and 500 GB of disk space for less than $1000”.\n",
        "\n",
        "To do this kind of retrieval, we first need to be able to look for expressions like 6 GHz or 500 GB or Mac or $999.99. In the rest of this section we’ll work out some simple regular expressions for this task.\n",
        "First, let’s complete our regular expression for prices. Here’s a regular expression for a dollar sign followed by a string of digits:\n",
        "\n",
        "/$[0-9]+/\n",
        "\n",
        "Note that the \\$ character has a different function here than the end-of-line function we discussed earlier. Most regular expression parsers are smart enough to realize that $ here doesn’t mean end-of-line\n",
        "\n",
        "![](https://i.imgur.com/ZjQJlob.png)\n",
        "\n",
        "Note in the regex101 platform we had to put in a \"\\\\\" before $ to make it work\n",
        "\n",
        "\n",
        "Now we just need to deal with fractions of dollars. We’ll add a decimal point\n",
        "and two digits afterwards:\n",
        "\n",
        "For example $1000.22\n",
        "\n",
        "Lets start from the beginning\n",
        "\n",
        "`\\$[0-9]+` -> this matches a $ followed by one or more digits\n",
        "\n",
        "`\\.[0-9]{1,2}` -> this matches a . followed by 1 or 2 digits\n",
        "\n",
        "But the .22 pattern can be there or not -> 0 or 1 times\n",
        "\n",
        "So `(\\.[0-9]{1,2}){0,1}`\n",
        "\n",
        "So the full pattern\n",
        "\n",
        "![](https://i.imgur.com/dyTQGKT.png)\n",
        "\n",
        "\n",
        "Lets look at the solution given in the text:\n",
        "\n",
        "\n",
        "`\\$[0-9]+` -> this matches a $ followed by one or more digits\n",
        "\n",
        "\n",
        "`\\$[0-9]+\\.[0-9][0-9]`  -> $ followed by one or more digits followed by . followed by 2 digits\n",
        "\n",
        "`\\$[0-9]+(\\.[0-9][0-9])?` -> making the entire . followed by 2 digits part optional (? matches bw 0->1 times)\n",
        "\n",
        "We just surround these with `(^|\\W)` - basically we match the start of a line or ny non-word character (equivalent to `[^a-zA-Z0-9_]`)\n",
        "\n",
        "Also we end the expression with `\\b` to indicate a word boundary so we dont match `$1000s`\n",
        "\n",
        "![](https://i.imgur.com/W8JSOc8.png)\n",
        "\n",
        "Finally we limit the dollars like:\n",
        "`(ˆ|\\W)\\$[0-9]{0,3}(\\.[0-9][0-9])?\\b`\n",
        "We can also make it: `(ˆ|\\W)\\$[0-9]{1,3}(\\.[0-9][0-9])?\\b` to limit expressions like `$.12`\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VE5s0G0wQszz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}