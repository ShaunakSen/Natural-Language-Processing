{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Real-World Python Machine Learning Tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOjH/RiPuGmV5jfoLbt4MEZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShaunakSen/Natural-Language-Processing/blob/master/Real_World_Python_Machine_Learning_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qm4Hfva_O8kk",
        "colab_type": "text"
      },
      "source": [
        "## Real-World Python Machine Learning Tutorial\n",
        "\n",
        "> Based on the YouTube tutorial by Keith Galli: link: https://www.youtube.com/watch?v=M9Itm95JzL0\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sweCnrJP_L5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "54edc774-77f8-469b-dc1d-ca03868ca7b1"
      },
      "source": [
        "!pip install rich"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rich in /usr/local/lib/python3.6/dist-packages (1.1.7)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from rich) (2.6.1)\n",
            "Requirement already satisfied: dataclasses<0.8,>=0.7; python_version >= \"3.6\" and python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from rich) (0.7)\n",
            "Requirement already satisfied: colorama<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from rich) (0.4.3)\n",
            "Requirement already satisfied: pprintpp<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from rich) (0.4.0)\n",
            "Requirement already satisfied: typing-extensions<4.0.0,>=3.7.4 in /usr/local/lib/python3.6/dist-packages (from rich) (3.7.4.2)\n",
            "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from rich) (0.9.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmZpAdx0N6YD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from rich import print as r_print\n",
        "import random\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn import svm\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnL4TReSRzb_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Sentiment:\n",
        "    NEGATIVE = 'NEGATIVE'\n",
        "    NEUTRAL = 'NEUTRAL'\n",
        "    POSITIVE = 'POSITIVE'\n",
        "\n",
        "\n",
        "class Review:\n",
        "    def __init__(self, text, score):\n",
        "        self.text = text\n",
        "        self.score = score\n",
        "        self.sentiment = self.get_sentiment()\n",
        "    \n",
        "    def get_sentiment(self):\n",
        "        if self.score <= 2:\n",
        "            return Sentiment.NEGATIVE\n",
        "        elif self.score == 3:\n",
        "            return Sentiment.NEUTRAL\n",
        "        else:\n",
        "            return Sentiment.POSITIVE\n",
        "\n",
        "class ReviewContainer:\n",
        "    \"\"\"\n",
        "    used to evenly split up the train and test reviews into +ve and -ve sentiments\n",
        "    \"\"\"\n",
        "    def __init__(self, reviews):\n",
        "        self.reviews = reviews\n",
        "\n",
        "    def get_text(self):\n",
        "        return [x.text for x in self.reviews]\n",
        "    def get_sentiment(self):\n",
        "        return [x.sentiment for x in self.reviews]\n",
        "\n",
        "    def evenly_distribute(self):\n",
        "        negative = list(filter(lambda x: x.sentiment == Sentiment.NEGATIVE, self.reviews))\n",
        "        positive = list(filter(lambda x: x.sentiment == Sentiment.POSITIVE, self.reviews))\n",
        "        print (f'Initial length of positive: {len(positive)}, negative: {len(negative)}')\n",
        "\n",
        "        positive_shrunk = positive[:len(negative)]\n",
        "\n",
        "        self.reviews = negative + positive_shrunk\n",
        "\n",
        "        print (f'Final length of positive: {len(positive_shrunk)}, negative: {len(negative)}')\n",
        "\n",
        "\n",
        "\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hq8kYyjQPv5z",
        "colab_type": "code",
        "outputId": "b4df0116-2143-47cd-8a3d-0583736812ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "file_name = './Books_small_10000.json'\n",
        "\n",
        "reviews = [] # [review_obj1, review_obj2, ...]\n",
        "\n",
        "# read the data and append to list\n",
        "with open(file_name) as f:\n",
        "    for line in f:\n",
        "        review = json.loads(line)\n",
        "        # create a Review obj\n",
        "        review_obj = Review(text=review['reviewText'], score=review['overall'])\n",
        "        reviews.append(review_obj)\n",
        "\n",
        "r_print (reviews[0].sentiment)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "POSITIVE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1GYREU8Zo7X",
        "colab_type": "code",
        "outputId": "71d512e2-b7f2-4b91-d6e5-59fbb1cef111",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print (f'Number of reviews: {len(reviews)}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of reviews: 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmJO2o9NTxPJ",
        "colab_type": "text"
      },
      "source": [
        "### Bag of words\n",
        "\n",
        "ML models work really well with numeric data and not so well with text data\n",
        "\n",
        "So we need a method to convert text to vectors\n",
        "\n",
        "![](https://i.ibb.co/V3ycp0n/diag1.png)\n",
        "\n",
        "The first 2 sentences are the training set and the last one is the test set\n",
        "\n",
        "Note: In the test set there are words like 'a' and 'very' that are not there in the training data\n",
        "\n",
        "So we simply ignore them\n",
        "\n",
        "### Split the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzBdjKDAQODW",
        "colab_type": "code",
        "outputId": "31dd2053-4f8b-429c-bf1b-e07857f2b9a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "training, test = train_test_split(reviews, test_size=0.33, random_state=42)\n",
        "\n",
        "print (len(training))\n",
        "\n",
        "print (training[0].text, training[0].sentiment)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6700\n",
            "Olivia Hampton arrives at the Dunraven family home as cataloger of their extensive library. What she doesn't expect is a broken carriage wheel on the way. Nor a young girl whose mind is clearly gone, an old man in need of care himself (and doesn&#8217;t quite seem all there in Olivia&#8217;s opinion). Furthermore, Marion Dunraven, the only sane one of the bunch and the one Olivia is inexplicable drawn to, seems captive to everyone in the dusty old house. More importantly, she doesn't expect to fall in love with Dunraven's daughter Marion.Can Olivia truly believe the stories of sadness and death that surround the house, or are they all just local neighborhood rumor?Was that carriage trouble just a coincidence or a supernatural sign to stay away? If she remains, will the Castle&#8217;s dark shadows take Olivia down with them or will she and Marion long enough to declare their love?Patty G. Henderson has created an atmospheric and intriguing story in her Gothic tale. I found this to be an enjoyable read, even if it isn&#8217;t my usual preferred genre. I think, with this tale, I got hooked on the old Gothic romantic style. So I think fans of the genre (and of lesbian romances) will enjoy it. POSITIVE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vFz9vt2rNQj",
        "colab_type": "code",
        "outputId": "5b9ea9ae-87bb-4b09-fba6-d427a3d8ed8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "### split up the reviews evenly\n",
        "review_container_tr = ReviewContainer(training)\n",
        "review_container_te = ReviewContainer(test)\n",
        "review_container_tr.evenly_distribute()\n",
        "review_container_te.evenly_distribute()\n",
        "\n",
        "\n",
        "print (f'Length of training data after shrinking is {len(review_container_tr.reviews)}')\n",
        "print (f'Length of test data after shrinking is {len(review_container_te.reviews)}')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial length of positive: 5611, negative: 436\n",
            "Final length of positive: 436, negative: 436\n",
            "Initial length of positive: 2767, negative: 208\n",
            "Final length of positive: 208, negative: 208\n",
            "Length of training data after shrinking is 872\n",
            "Length of test data after shrinking is 416\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RG3HCPMoat5m",
        "colab_type": "text"
      },
      "source": [
        "Now we split the training and test data into X and y (inputs and ops):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrNIb1UKabkq",
        "colab_type": "code",
        "outputId": "20d5f5a7-a3aa-46d1-8ee6-2f0615f6470e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "train_X = review_container_tr.get_text()\n",
        "train_y = review_container_tr.get_sentiment()\n",
        "\n",
        "test_X = review_container_te.get_text()\n",
        "test_y = review_container_te.get_sentiment()\n",
        "\n",
        "print (train_X[0], train_y[0], test_X[0], test_y[0])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "It was just one of those books that never went anywhere. I like books that get your attention in the beginning and not drag out until a quarter way through. I decided to give it an early death - delete! NEGATIVE Story is very inaccurate with modern words, phrases and actions.  In the second chapter the author has the bagpipes playing \"Amazing Grace\" and according to her it is a song as old as time.  As someone who learned to play Amazing Grace on the piano I can state for a fact the song is not old as time. It was not even published until 1779; author has the book set in 1714. 65 years before John Newton wrote and published the songFiona and Juliet speak like they are in the 21 century. Not a young miss in the early 18th century.I have no problem reading about God in books. My problem is when authors take too much leeway and write using modern phrases in historical books.Really, wondering if this author did any 'real' research or just used what she remembered from high school world history?Really, how many young ladies will tell someone they just met that they were compromised? How many young ladies are going to travel with out any type of female companion? Juliet is traveling with 3 men. Only one of them is a younger brother. Not happening for the year this book is set in.  Author needs to complete research before attempting to write anything historical. No unmarried lady in this time period would allow any man to sleep on the floor next to her bed. What was the author thinking? If your going to write a historical romance book at least research before writing. Remember Google is your friend.This is NOT a historical romance book.  This IS a contemporary romance with some historical stuff thrown in.The woman on the cover should give away everything about how modern this book is written. Just look at the hair color. Anyone can tell it is from a box.Author going on my never read and waste money on again.  BIG DISAPPOINTMENT! NEGATIVE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alcs8PdkbTX0",
        "colab_type": "code",
        "outputId": "3abb8ba5-4fc4-43d2-ffa8-f683fd542f6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "vectorizer = CountVectorizer()\n",
        "train_X_vectors = vectorizer.fit_transform(train_X)\n",
        "\n",
        "print (train_X_vectors.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(872, 8906)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GB4wmOG_sNDX",
        "colab_type": "code",
        "outputId": "b6416725-5e43-4ac2-8863-437a68f56be4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print (vectorizer.get_feature_names()[4277])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "it\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBIPl1L7ro1s",
        "colab_type": "code",
        "outputId": "d7e61862-7b0e-48ff-b9f3-52ee25f5e7ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        }
      },
      "source": [
        "print (train_X_vectors[0])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 4277)\t2\n",
            "  (0, 8608)\t1\n",
            "  (0, 4409)\t1\n",
            "  (0, 5514)\t1\n",
            "  (0, 5478)\t1\n",
            "  (0, 7984)\t1\n",
            "  (0, 996)\t2\n",
            "  (0, 7925)\t2\n",
            "  (0, 5350)\t1\n",
            "  (0, 8666)\t1\n",
            "  (0, 473)\t1\n",
            "  (0, 4684)\t1\n",
            "  (0, 3374)\t1\n",
            "  (0, 8883)\t1\n",
            "  (0, 634)\t1\n",
            "  (0, 4034)\t1\n",
            "  (0, 7929)\t1\n",
            "  (0, 816)\t1\n",
            "  (0, 423)\t1\n",
            "  (0, 5408)\t1\n",
            "  (0, 2430)\t1\n",
            "  (0, 5589)\t1\n",
            "  (0, 8403)\t1\n",
            "  (0, 6305)\t1\n",
            "  (0, 8627)\t1\n",
            "  (0, 8005)\t1\n",
            "  (0, 2042)\t1\n",
            "  (0, 8052)\t1\n",
            "  (0, 3393)\t1\n",
            "  (0, 416)\t1\n",
            "  (0, 2526)\t1\n",
            "  (0, 2017)\t1\n",
            "  (0, 2081)\t1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f4OX8p2rwv0",
        "colab_type": "text"
      },
      "source": [
        "This is basically like a sparse matrix\n",
        "\n",
        "It only prints the positions of the non-zero elements\n",
        "\n",
        "We can see that for the first review the word at idx 350 occurs twice nad this is the word 'and' and it does indeed occur twice in the review\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tc506zcLruc5",
        "colab_type": "code",
        "outputId": "d2134037-f529-4289-c837-d8293b71c4e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print (train_X[0])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "It was just one of those books that never went anywhere. I like books that get your attention in the beginning and not drag out until a quarter way through. I decided to give it an early death - delete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkbDalw7v0s1",
        "colab_type": "text"
      },
      "source": [
        "Now we transfor the test data using the same fitted model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltKxToUSv3th",
        "colab_type": "code",
        "outputId": "93678a12-62b4-4a30-d92d-f9835cd7861f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "test_X_vectors = vectorizer.transform(test_X)\n",
        "\n",
        "print (test_X_vectors.shape)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(416, 8906)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybsZtu7ewaWr",
        "colab_type": "text"
      },
      "source": [
        "Now our final data is `train_X_vectors, train_y` and `test_X_vectors, test_y` and we want to create our model for this data\n",
        "\n",
        "### Classification \n",
        "\n",
        "\n",
        "#### Linear SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYkX0cCowYxS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf_svm = svm.SVC(kernel='linear')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRbHZD3txUxP",
        "colab_type": "code",
        "outputId": "dda90287-e4f0-4902-bc7f-fed5492a193f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "clf_svm.fit(train_X_vectors, train_y)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vlNDdEQxhgv",
        "colab_type": "code",
        "outputId": "933c10fd-8693-4083-972b-5650484914f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "test_X[0], test_y[0]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Story is very inaccurate with modern words, phrases and actions.  In the second chapter the author has the bagpipes playing \"Amazing Grace\" and according to her it is a song as old as time.  As someone who learned to play Amazing Grace on the piano I can state for a fact the song is not old as time. It was not even published until 1779; author has the book set in 1714. 65 years before John Newton wrote and published the songFiona and Juliet speak like they are in the 21 century. Not a young miss in the early 18th century.I have no problem reading about God in books. My problem is when authors take too much leeway and write using modern phrases in historical books.Really, wondering if this author did any \\'real\\' research or just used what she remembered from high school world history?Really, how many young ladies will tell someone they just met that they were compromised? How many young ladies are going to travel with out any type of female companion? Juliet is traveling with 3 men. Only one of them is a younger brother. Not happening for the year this book is set in.  Author needs to complete research before attempting to write anything historical. No unmarried lady in this time period would allow any man to sleep on the floor next to her bed. What was the author thinking? If your going to write a historical romance book at least research before writing. Remember Google is your friend.This is NOT a historical romance book.  This IS a contemporary romance with some historical stuff thrown in.The woman on the cover should give away everything about how modern this book is written. Just look at the hair color. Anyone can tell it is from a box.Author going on my never read and waste money on again.  BIG DISAPPOINTMENT!',\n",
              " 'NEGATIVE')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_979BehyAZh",
        "colab_type": "code",
        "outputId": "e8d65816-afd2-4fbb-9433-f8472c347574",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "clf_svm.predict(test_X_vectors[0])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['NEGATIVE'], dtype='<U8')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMW9NPTSyFxV",
        "colab_type": "text"
      },
      "source": [
        "So it predicts the first test review correctly\n",
        "\n",
        "#### Decison Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MT4oKomTyDUA",
        "colab_type": "code",
        "outputId": "6f682717-fe70-4fd2-b068-e7d027e56a59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "clf_DT = DecisionTreeClassifier()\n",
        "clf_DT.fit(train_X_vectors, train_y)\n",
        "clf_DT.predict(test_X_vectors[0])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['POSITIVE'], dtype='<U8')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhHRNlg21g70",
        "colab_type": "text"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9lOnYyuy_nb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "42c236b5-5832-43ff-8334-121ed1382eb4"
      },
      "source": [
        "# Mean Accuracy\n",
        "print(clf_svm.score(test_X_vectors, test_y))\n",
        "print(clf_DT.score(test_X_vectors, test_y))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7980769230769231\n",
            "0.6153846153846154\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43EXd3Lz1rv0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8f22d9a1-5b81-4c84-f4f5-37a139d4546b"
      },
      "source": [
        "f1_score(y_true=test_y, y_pred=clf_svm.predict(test_X_vectors), average=None, labels=[Sentiment.POSITIVE, Sentiment.NEGATIVE])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.8028169 , 0.79310345])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHjACwL02LXy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f1_score(y_true=test_y, y_pred=clf_DT.predict(test_X_vectors), average=None, labels=[Sentiment.POSITIVE, Sentiment.NEGATIVE])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "So5uEboN0PaA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}